{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home This is a list of cheatsheets and notes. Links: GEA1000 midterms cheatsheet GEA1000 finals cheatsheet CS2040S midterms cheatsheet CS2040S finals cheatsheet CS2103/T notes DSA notes CS2106 notes","title":"Home"},{"location":"#home","text":"This is a list of cheatsheets and notes. Links: GEA1000 midterms cheatsheet GEA1000 finals cheatsheet CS2040S midterms cheatsheet CS2040S finals cheatsheet CS2103/T notes DSA notes CS2106 notes","title":"Home"},{"location":"cs2103t/cs2103t-notes/","text":"CS2103/T Notes CS2103/T Notes Java Varargs Programming Paradigm Object-Oriented Programming (OOP) Requirements Non-functional Requirements Quality of Requirements Gathering Requirements Specifying Requirements Design Design Fundamentals Modeling Design Patterns Singleton Pattern Abstraction Occurrence Pattern Facade Pattern Command Pattern Model View Controller (MVC) Pattern Observer Pattern Design Approaches Principles S ingle Responsibility Principle O pen-Closed Principle L iskov Substitution Principle I nterface Segregation Principle D ependency Inversion Principle Separation of Concerns Principle Law of Demeter YAGNI Principle DRY Principle Brooks' Law UML Class Diagrams Notation \u2014 Class Diagrams Associations \u2014 Class Diagrams Navigability Multiplicity Dependencies Composition (Has-A) Aggregation Inheritance (Is-A) Objects Diagrams Notation \u2014 Objects Diagrams Sequence Diagrams Notation \u2014 Sequence Diagrams OODM Activity Diagrams Notation \u2014 Activity Diagrams Project Management Revision Control Project Planning Work Breakdown Structure Milestones Buffers Issue Trackers GANTT Charts PERT Charts SDLC Process Models Sequential Models Iterative Models Agile Models XP Scrum Unified Process CMMI Coding Standards Naming Layout Statements Classes and interfaces Methods Types Variables Loops Conditionals Comments Implementation Coding Quality Refactoring Documentation Types Guidelines Error Handling Integration Reuse Quality Assurance Code Reviews Static Analysis Formal Verification Test Case Design Testing Regression Testing Developer Testing Unit Testing Integration Testing System Testing Alpha and Beta Testing Dogfooding Exploratory and Scripted Testing User Acceptance Testing Test Automation Testing Java Varargs Syntactic sugar type feature that allows writing a method that can take a variable number of arguments. public static void search(String ... keywords){ // method body } Programming Paradigm Guides programmers to analyse programmig problems ad structure programmig solutions in a specific way Object-Oriented Programming (OOP) Views the world as a network of interacting objects Tries to create a similar object network inside the computer's memory so that a similar result can be achieved programmtically Requirements A software requirement specifies a need to be fulfilled by the software product. A software project may be Brownfield project i.e., develop a product to replace/update an existing software product Greenfield project i.e., develop a totally new system from scratch Requirements come from stakeholders Requirements can be divided into: Functional requirements specify what the system should do Non-functional requirements specify the constraints under which the system is developed and operated Non-functional Requirements Specify the constraints under which the system is developed and operated NFRs are easier to miss Sometimes NFRs are critical to the success of the software Quality of Requirements Characteristics of well-defined requirements: Unambiguous Testable (verifiable) Clear (concise, terse, simple, precise) Correct Understandable Feasible (realistic, possible) Independent Atomic Necessary Implementation-free (i.e. abstract) Set of requirements as a whole should be: Consistent Non-redundant Complete Gathering Requirements Brainstorming session No \"bad\" ideas (aim is to generate ideas; not to validate them) Product surveys Studying existing products can unearth shortcomings of existing solutions that can be addressed by a new product Observation Observing users in their natural work environment can uncover product requirements User surveys Surveys can be used to solicit responses and opinions from a large number of stakeholders regarding a current product or a new product Interviews Interviewing stakeholders and domain experts can produce useful information about project requirements Focus groups Focus groups are a kind of informal interview within an interactive group setting Prototyping A prototype is a mock up, a scaled down version, or a partial system constructed to get users feedback to validate a technical concept (a \"proof-of-concept\" prototype) to give a preview of what is to come, or to compare multiple alternatives on a small scale before committing fully to one alternative for early field-testing under controlled conditions Specifying Requirements Feature list A list of features of a product grouped according to some criteria such as aspect, priority, order of delivery, etc User stories Short, simple descriptions of a feature told from the perspective of the person who desires the new capability, usually a user or customer of the system Format: As a {user type/role} I can {function} so that {benefit} {benefit} can be omitted if it is obvious Can: Add more characteristics to the {user role} , e.g. As a forgetful user, ... Write user stories at various levels (epic/theme) Add conditions of satisfaction to a user story Include: Priority: how important the user story is Size: the estimated effort to implement the user story Urgency: how soon the feature is needed Convenient for scoping, estimation, and scheduling Less details compared to traditional requirements specifications Captures non-functional requirements too because even NFRs must benefit some stakeholder Handy for recording requirements during early stages of requirements gathering Use cases Set of sequences of actions, including variants, that a system performs to yield an observable result of value to an actor Describes an interaction between the user and the system for a specific functionality of the system Only externally visible behavior (omit UI details) Actor : An actor (in a use case) is a role played by a user. can be a human or another system. not part of the system; they reside outside the system. Main Success Scenario (MSS) describes the most straightforward interaction for a given use case, which assumes that nothing goes wrong Extensions are \"add-on\"s to the MSS that describe exceptional/alternative flow of events Glossary Serves to ensure that all stakeholders have a common understanding of the noteworthy terms, abbreviations, acronyms etc Supplementary requirements This section can be used to capture requirements that do not fit elsewhere Typically, this is where most Non-Functional Requirements will be listed Design Design Fundamentals Abstraction Data abstraction: abstracting away the lower level data items and thinking in terms of bigger entities Control abstraction: abstracting away details of the actual control flow to focus on tasks at a higher level Coupling Coupling is a measure of the degree of dependence between components, classes, methods, etc. Low coupling indicates that a component is less dependent on other components High coupling is discouraged: maintenance, integration, testing and reuse of module is harder. Zero coupling is not possible for non-trivial software. Types: content, common/ global, data, external, subclass, temporal Modeling A model provides a simpler view of a complex entity because a model captures only a selected aspect. This omission of some aspects implies models are abstractions. Multiple models of the same entity may be needed to capture it fully. Models can be used as a blueprint for creating software. Design Patterns An elegant reusable solution to a commonly recurring problem within a given context in software design Common format to describe a pattern: Context: The situation or scenario where the design problem is encountered Problem: The main difficulty to be resolved Solution: The core of the solution. It is important to note that the solution presented only includes the most general details, which may need further refinement for a specific context Anti-patterns (optional): Commonly used solutions, which are usually incorrect and/or inferior to the Design Pattern. Consequences (optional): Identifying the pros and cons of applying the pattern Other useful information (optional): Code examples, known uses, other related patterns, etc 23 Design Patterns divided into 3 categories: Creational: About object creation. They separate the operation of an application from how its objects are created. Abstract Factory, Builder, Factory Method, Prototype, Singleton Structural: About the composition of objects into larger structures while catering for future extension in structure. Adapter, Bridge, Composite, Decorator, Facade , Flyweight, Proxy Behavioral: Defining how objects interact and how responsibility is distributed among them. Chain of Responsibility, Command , Interpreter, Template Method, Iterator, Mediator, Memento, Observer , State, Strategy, Visitor Singleton Pattern When to use: Requires only one instance of a class There is a risk of creating multiple objects by mistake Creating such multiple objects has real negative consequences How to use: Private constructor with a public class-level method to access the single instance Optional <<Singleton>> UML stereotype to indicate role Pros: Easy to apply Effective in achieving its goal with minimal extra work Provides an easy way to access the singleton object from anywhere in the code base Cons: Acts like a global variable that increases coupling across the code base In testing, its difficult to replace Singleton objects with stubs (static methods cannot be overridden). In testing, singleton objects carry data from one test to another Abstraction Occurrence Pattern When to use: Group of similar entities with common information Also differing in significant ways How to use: Split entity into 2 classes 1 object for common information ( Abstraction ) and many for unique information ( Occurrence ) Facade Pattern When to use: Components need to access functionality deep inside other components. How to use: Create a Facade class that sits between users of component and component internals All access to the component happens through the Facade class Command Pattern When to use: Have a system is required to execute a number of commands Each doing a different task How to use: Create a general Command object such that it can be used without knowing the exact type of command (using polymorphism) Example: Command interface in AB3 where all Commands implement this interface and have an execute method Model View Controller (MVC) Pattern When to use: Support storage/retrieval of information Displaying of information to the user (often via multiple UIs having different formats) Changing stored information based on external inputs How to use: Split the data, presentation and control logic into 3 parts: View: Displays data, interacts with the user, and pulls data from the model if necessary. Controller: Detects UI events such as mouse clicks and button pushes, and takes follow up action. Updates/changes the model/view when necessary. Model: Stores and maintains data. Updates the view if necessary. In a simple UI where there is only one view, Controller and View can be combined as one class. Observer Pattern When to use: An object (possibly more than one) needs to be notified when a change happens to another object How to use: Force the communication through an interface known to both parties Have all observers implement an Observer interface Add all observers to the observee's observer list When there is an update, notify all added observers Design Approaches Top-down: Design the high-level design first and flesh out the lower levels later Useful when designing big and novel systems where the high-level design needs to be stable before lower levels can be designed Bottom-up: Design lower level components first and put them together to create the higher-level systems later. Not usually scalable for bigger systems. One instance where this approach might work is when designing a variation of an existing system or re-purposing existing components to build a new system Mix: Design the top levels using the top-down approach but switch to a bottom-up approach when designing the bottom levels Agile: Emergent and not defined up front Overall system design will emerge over time, evolving to fulfill new requirements and take advantage of new technologies as appropriate Just enough initial architectural modeling at the very beginning of a project to get your team going Does not produce a fully documented set of models in place before you may begin coding Principles S ingle Responsibility Principle Definition: A class should have one, and only one, reason to change If a class has only one responsibility, it needs to change only when there is a change to that responsibility Good way of identifying classes during the design phase O pen-Closed Principle Definition: A module should be open for extension but closed for modification. That is, modules should be written so that they can be extended, without requiring them to be modified Aims to make a code entity easy to adapt and reuse without needing to modify the code entity itself Separating the specification (i.e. interface) of a module from its implementation L iskov Substitution Principle Definition: Derived classes must be substitutable for their base classes Subclass should not be more restrictive than the behavior specified by the superclass LSP is not followed when substituting a subclass object for a superclass object breaks the functionality of the code I nterface Segregation Principle Definition: No client should be forced to depend on methods it does not use Can depend on an interface with just the methods it need, instead of the entire class D ependency Inversion Principle Definition: High-level modules should not depend on low-level modules. Both should depend on abstractions Abstractions should not depend on details. Details should depend on abstractions Separation of Concerns Principle Definition: To achieve better modularity, separate the code into distinct sections, such that each section addresses a separate concern A concern is a set of information that affects the code of a computer program Reduces functional overlaps Limits ripple effect when changes are introduced to a specific part of system Can be applied at the class level as well as higher levels Lead to higher cohesion and lower coupling Law of Demeter Definition: An object should have limited knowledge of another object An object should only interact with objects that are closely related to it Aims to prevent objects from navigating the internal structures of other objects Method foo of an object obj should invoke only the methods of the following kinds of objects: Object obj itself Objects passed as parameters of foo Objects created/instantiated in foo (directly or indirectly) Objects from the direct association of obj YAGNI Principle Definition: You Aren't Gonna Need It! Do not add code simply because 'you might need it in the future' Some capability you presume your software needs in the future should not be built now Do not have perfect information about the future The extra work might go to waste when some of your predictions fail to materialize DRY Principle Definition: Don't Repeat Yourself Every piece of knowledge must have a single, unambiguous, authoritative representation within a system Guards against the duplication of information Examples of violations: Functionality being implemented twice even if the two implementations are different Value of a system-wide timeout being defined in multiple places Brooks' Law Definition: Adding people to a late project will make it later The additional communication overhead will outweigh the benefit of adding extra manpower, especially if done near a deadline UML Class Diagrams Used to model class structures of an OO solution Describe the structure (but not behaviour) of OOP solution Notation \u2014 Class Diagrams Visibility: + for public | - for private | # for protected | ~ package private (default) Class-level methods/ attributes are underlined <<interface>> <<enumeration>> {abstract} or abstract OK to omit: Methods Associations \u2014 Class Diagrams Association roles appears on end that plays that role An association can be shown as a line between the two classes or as an attribute in one of the classes (but not both). Navigability Solid arrow The concept of which object in the association knows about the other object. E.g. Navigability is from Box to Rope , b will have reference to r but not vice versa. One can navigate from b to r using b 's object reference of r . Multiplicity 0..X Number of X is on end nearer X. The aspect of an OOP solution that dictates how many objects take part in each association. Dependencies Dotted line A need for one class to depend on another without having a direct association in the same direction. Composition (Has-A) Shaded diamond Diamond is on the end of the whole. A composition is an association that represents a strong whole-part relationship. When the whole is destroyed, parts are destroyed too (parts cannot exist without whole). Cannot be cyclical links. Aggregation Non-shaded/hollow diamond Diamond is on the end of the container. An aggregation is an association that represents a container-contained relationship. Similar to that of composition except the containee object can exist even after the container object is deleted. Weaker relationship than composition. Aggregation represents a container-contained relationship. It is a weaker relationship than composition. Inheritance (Is-A) Triangle arrow (inheriting class - class or interface - interface) Triangle arrow with dotted line: implementing an interface Does not matter whether the triangle is filled or empty Points to parent class Inheritance implies the derived class can be considered as a sub-type of the base class (and the base class is a super-type of the derived class), resulting in an is a relationship. Objects Diagrams Used to model object structure of an OO solution Multiple object diagrams can correspond to a single class diagram Notation \u2014 Objects Diagrams Object names are underlined If there is inheritance, show either parent class or child class (not both) MUST omit: Methods Multiplicities OK to omit: Object name Variable name/ value Attributes compartment (if not relevant) Association labels/ roles (if not relevant) Sequence Diagrams Notation \u2014 Sequence Diagrams Arrows representing method calls: solid lined arrows Arrows representing method returns: dashed lined arrows Class/object name is not underlined Use an X at the end of the lifeline of an object to show its deletion Self-invocation calls is denoated by an arrow from the bar to itself Method calls to static methods are received by the class itself You can use <<class>> to show that a participant is the class itself All frames should use a rectangle with a clip on the bottom-right corner loop frame: indicate a loop (can execute 0 times) loop [condition] alt frame: indicate alternative paths alt [condition] No more than one alternative partitions be executed in an alt frame opt frame: indicate optional paths opt [condition] ref frame: allow a segment of the interaction to be omitted and shown as a separate sequence diagram ref diagram title (in the original diagram) sd diagram title (sub-sequence diagram shown in this frame) par frame: indicate parallel paths (can happen in any order) The corresponding Java implementation is likely to be multi-threaded- Keywords are loop (while), opt (if) and alt (if elseif) OK to omit: Activation bar Return arrows Activation bar of self-invocation OODM Similar to class diagram notation but must omit: methods navigability Do not contain solution-specific classes (classes that do not exist in the problem domain e.g. DatabaseConnection) Activity Diagrams Models workflows Notation \u2014 Activity Diagrams Action : rounded corners rectangle Denotes a single step in an activity. Control flow : arrow-head line Denotes the flow of control from one action to the next. Start node : shaded circle Denotes the start of the activity End node : inner shaded circle with with a surrounding circle Denotes the end of the activity Branch node : diamond square with two [conditions] Denotes the start of alternate path. Exactly one of the guard conditions should be true. Merge node : diamond square Denotes the end of alternative paths Fork node : bar Denotes the start of concurrent flows of cotntrol. Join node : bar Denotes the end of parallel paths Rake : rake symbol Denotes that the action is described in another subsidiary activity diagram Swim lanes : partition Denotes who is doing which action (also called swimlane diagrams) OK to do: Multiple arrows can start from the same corner of a branch node Omit merge node if it there's no ambiguity Omit [Else] condition. Project Management Revision Control Process of managing multiple versions of a piece of information Will track the history and evolution of your project Makes it easier for to collaborate Repository is the database that stores the revision history. Using History Tag a specific commit to identify To see what changed: diff To restore the state of the working directory at point in the past: checkout the commit Remote Repositories git clone a repo to create a (local) copy Original repo is referred to as upstream repo git pull from one repo to another git push new commits in one repo to another Fork is a remote copy of a remote repo Pull request is a mechanism for contributing code to a remote repo Branching is the process of evolving multiple versions of the software in parallel. Merge conflicts happen when you try to merge two branches that had changed the same part of the code and the revision control software (RCS) cannot decide which changes to keep. Centralized RCS uses a central remote repo that is shared by the team. Distributed RCS allows multiple remote repos and pulling and pushing can be done among them in arbitrary ways. Forking flow : the 'official' version of the software is kept in a remote repo designated as the 'main repo'. All team members fork the main repo and create pull requests from their fork to the main repo. Feature branch workflow is similar to forking workflow except there are no forks. Centralized flow is similar to the feature branch workflow except all changes are done in the master branch. Project Planning Work Breakdown Structure Depicts information about tasks and their details in terms of subtasks Can also include prerequisite tasks and effort estimates for each task Effort is traditionally measured in man hour/day/month All tasks should be well-defined Task ID Task Estimated Effort Prerequisite Task A Analysis 1 man hour - B Design 2 man day A Milestones End of a stage which indicates significant progress Should account for dependencies and priorities when deciding on the features to be delivered at a certain milestone Each intermediate product release is a milestone Buffers Time set aside to absorb unforeseen delays Very important to include because effort/time estimations are notoriously hard Do not inflate task estimates to create hidden buffers (have explicit buffers instead) Reason: With explicit buffers, it is easier to detect incorrect effort estimates which can serve as feedback to improve future estimates Issue Trackers Issue trackers (sometimes called bug trackers) are commonly used to track task assignment and progress GANTT Charts 2-D bar-chart Drawn as time vs tasks Solid bar represents the main task (composed of a number of subtasks) Grey bars represent subtasks Diamond shape indicates an important deadline/deliverable/milestone PERT Charts Program Evaluation Review Technique Shows the order/sequence of tasks Directed graph: Nodes or vertices capture the effort estimations of tasks Arrows depict the precedence between tasks Helps determine the following: Order of tasks Which tasks can be done concurrently Shortest possible completion time Critical path (path where any delay can directly affect the project duration, hence it is important to ensure tasks on the critical path are completed on time) SDLC Process Models Software development goes through different stages such as requirements, analysis, design, implementation and testing Collectively known as the software development life cycle (SDLC) Sequential Models Views software development as a linear process Also called waterfall model When one stage of the process is completed, it produces some artifacts to be used in the next stage A strict sequential model project moves only in the forward direction Pros: Work well for a project that produces software to solve a well-understood problem Cons: Real-world projects often tackle problems that are not well-understood at the beginning Iterative Models Advocates producing the software by going through several iterations Each iteration produces a new version of the product that builds on the version produced in previous iteration Breadth-first An iteration evolves all major components and all functionality areas in parallel Depth-first An iteration focuses on fleshing out only some components or some functionality area. Early depth-first iterations might not produce a working product. A project can be done as a mixture of breadth-first and depth-first iterations Agile Models XP Extreme programming Stresses customer satisfaction Aims to make developers confidently respond to changing requirements (even late in life cycle) Emphasizes teamwork Improve in: communication, simplicity, feedback, respect and courage Has a set of simple rules Scrum Scrum is a process skeleton that contains sets of practices and predefined roles. The main roles in Scrum are: The Scrum Master , who maintains the processes (typically in lieu of a project manager). The Product Owner , who represents the stakeholders and the business. The Team, a cross-functional group who do the actual analysis, design, implementation, testing, etc. A Scrum project is divided into iterations called Sprints . A key principle of Scrum is its recognition that during a project the customers can change their minds about what they want and need. The daily scrum meeting is not used as a problem-solving or issue resolution meeting. Issues that are raised are taken offline and usually dealt with by the relevant subgroup immediately after the meeting. Members answer these questions What did you do yesterday? What will you do today? Are there any impediments in your way? Unified Process Flexible and customizable process model framework Consists of four phases: inception, elaboration, construction and transition Phase Activities Typical Artifacts Inception Understand the problem and requirements Communicate with customer Plan the development effort Basic use case model Rough project plan Project vision and scope Elaboration Refine and expand requirements Determine a high-level design System architecture Various design models Prototype Construction Major implementation effort to support the use cases identified Design models are refined and fleshed out Testing of all levels are carried out Multiple releases of the system Test cases of all levels System release Transition Ready the system for actual production use Familiarize end users with the system Final system release Instruction manual CMMI Capability Maturity Model Integration Defines 5 maturity levels for a process (specifies criteria): Level 1: Initial Processes unpredictable, poorly controlled and reactive Level 2: Managed Processes characterised for projects and is often reactive Level 3: Defined Processes characterised for organisations and is proactive Level 4: Quantitatively Managed Processes measured and controlled Level 5: Optimizing Focus on process improvement Coding Standards Naming Names representing packages should be in all lower case. Class/ enum names must be nouns and written in PascalCase. Variable names must be in camelCase. Constant names must be in SCREAMING_SNAKE_CASE. Names representing methods must be verbs and written in camelCase. Abbreviation and acronyms should not be uppsercase when used as part of a name. All names should be written in English. Variables with a large scope should have long names, variables with a small scope can have short names. Boolean variables/ methods should be named to sound like booleans. Plural form should be used on names representing a collection of objects. Iterator variables can be called i, j, k. Associated constants should have a common prefix. Layout Basic indentation should be 4 spaces. Line length should be no longer than 120 characters. Place line break to improve readability. Use egyptian style brackets. Method definitions should have the following form: public void someMethod() throws SomeException { ... } if-else class of statements should have the following form: if (condition) { statements; } for statement should have the following form: for (initialization; condition; update) { statements; } while statement should have the following form: while (condition) { statements; } switch statement should have the following form: switch (condition) { case ABC: statements; //Fallthrough case DEF: statements; break; } try-catch statement should have the following form: try { statements; } catch (Exception exception) { statements; } White space within a statement Operators should be surrounded by a space character Java reserved words should be followed by a white space Commas should be followed by a white space Colons should be surrounded by white space when used as binary/ ternary operator Logical units within a block should be separated by one blank line Statements Put every class in a package Put related classes in a single package The ordering of import statements must be consistent Imported classes should always be listed explicity (not *) Classes and interfaces Class/Interface documentation (Comments) class or interface statement Class (static) variables in the order public, protected, package (no access modifier), private Instance variables in the order public, protected, package (no access modifier), private Constructors Methods (no specific order) Methods Method modifiers should be given in the following order: <access> static abstract synchronized <unusual> final native Types Array specifiers must be attached to the type not the variable int[] a = new int[20]; Variables Variables should be initialized where they are declared and they should be declared in the smallest scope possible. Class variables should never be declared public. Avoid unnecessary use of this with fields. Loops Loop body should be wrapped by curly brackets irrespective of how many lines there are in the body. Conditionals Conditional should be put on a separate line. Single statement conditionals should still be wrapped by curly brackets. Comments All comments should be written in English. Write descriptive header comments for all public classes/ methods. All non-trivial private methods should carry header comments. Javadoc comments should have the following form: /** * Returns lateral location of the specified position. * If the position is unset, NaN is returned. * * @param x X coordinate of position. * @param y Y coordinate of position. * @param zone Zone of position. * @return Lateral location. * @throws IllegalArgumentException If zone is <= 0. */ public double computeLocation(double x, double y, int zone) throws IllegalArgumentException { //... } Comments should be indented relative to their position in the code. while (true) { // Do something something(); } Implementation Coding Quality Avoid long methods Avoid deep nesting Avoid complicated expressions Avoid magic numbers Make the code obvious Structure code logically Do not 'trip up' reader Avoid unused paramters in method signature Similar things that look different Different things that look similar Multiple statements in the same line Practice KISSing Keep it simple, stupid Do not try to write 'clever' code Avoid premature optimizations SLAP hard Single Level of Abstraction Principle Avoid having multiple levels of abstraction within a code fragment Make the happy path prominent Naming: Use nouns for things and verbs for actions Use standard words Use name to explain Not too long, not too short Avoid misleading names Refactoring The process of improving a program's internal structure in small steps without modifying its external behavior is called refactoring Refactoring is not rewriting and not bug fixing (alters external behaviour). Benefits: hidden bugs become easier to spot improve performance Refactoring can result in regression Consolidate Duplicate Conditional Fragments // BEFORE if (isSpecialDeal()) { total = price * 0.95; send(); } else { total = price * 0.98; send(); } // AFTER if (isSpecialDeal()) { total = price * 0.95; } else { total = price * 0.98; } send(); Extract Method (opposite of this is inline method) from: //BEFORE void printOwing() { printBanner(); // print details System.out.println(\"name: \" + name); System.out.println(\"amount \" + getOutstanding()); } //AFTER void printOwing() { printBanner(); printDetails(getOutstanding()); } void printDetails(double outstanding) { System.out.println(\"name: \" + name); System.out.println(\"amount \" + outstanding); } Documentation Developer-as-user: API documentaion or tutorial-style instructional documentation Developer-as-maintainer: how a system or component is designed implemented and tested Types Tutorials (learning-oriented) How-to guides (goal-oriented) Explanation (understanding-oriented) Reference (information-oriented) Guidelines Top-down, not bottom-up The reader can travel down a path she is interested in until she reaches the component she is interested to learn in-depth Comprehensibility Use plenty of diagrams, examples, simple and direct explanations Document minimally but sufficiently 'just enough' developer documentation Error Handling Exceptions are used to deal with 'unusual' but not entirely unexpected situations that the program might encounter at runtime. After a method throws an exception, the runtime system attempts to find something to handle it in the call stack. Assertions are used to define assumptions about the program state so that the runtime can verify them. Assertions can be disabled without modifying the code. Java disables assertions by default. Assertions are used to define assumptions about the program state so that the runtime can verify them. Recommended that assertions be used liberally in the code. assertEquals is a JUnit method and only used in test classes. Logging is the deliberate recording of certain information during a program execution for future reference. Defensive programming is proactively eliminating any room for things to go wrong. Enforcing compulsory associations Enforcing 1-to-1 association Enforcing referential integrity (prevents case where A says B is X but B says B is Y) Design-by-contract approach is an approach for designing software that requires defining formal, precise and verifiable interface specifications for software components. Code first checks if the preconditions have been met. Integration Timing and frequency: Late and One Time : wait till all components are completed and integrate all finished components near the end of the project Not reccommended because integration often causes many component incompatibilities which can lead to delivery delays Early and Frequent : integrate early and evolve each part in parallel, in small steps, re-integrating frequently Extent: Big-bang integration : integrate all components at the same time Not reccommended because it will uncover too many problems at the same time Incremental integration : integrate a few components at a time (integration problems surface in a more manageable way) Direction: Top-down integration : higher-level components are integrated before bringing in the lower-level components +: Higher-level problems can be discovered early -: Requires the use of stubs in place of lower level components Bottom-up integration : the reverse of top-down integration When integrating lower level components, drivers may be needed to test the integrated components, because UI may not be integrated yet Sandwich integration : a mix of top-down and bottom-up approaches, do both and meet in the middle Reuse API : An Application Programming Interface (API) specifies the interface through which other programs can interact with a software component. It is a contract between the component and its clients. Library : A library is a collection of modular code that is general and can be used by other programs. Frameworks : A software framework is a reusable implementation of a software (or part thereof) providing generic functionality that can be selectively customized to produce a specific application. Some frameworks provide a complete implementation of a default behavior which makes them immediately usable. (e.g. Eclipse) Platforms : A platform provides a runtime environment for applications. Cloud computing : Cloud computing is the delivery of computing as a service over the network, rather than a product running on a local machine. Infrastructure as a service (IaaS) delivers computer infrastructure as a service. Platform as a service (PaaS) provides a platform on which developers can build applications. Software as a service (SaaS) allows applications to be accessed over the network instead of installing them on a local machine. Quality Assurance Quality Assurance = Validation + Verification Code Reviews Systematic examination of code with the intention of finding where the code can be improved Three types covered: PR reviews In pair programming Formal inspections Advantages over testing: It can detect functionality defects as well as other problems such as coding standard violations. It can verify non-code artifacts and incomplete code. It does not require test drivers or stubs. Disadvantages: It is a manual process and therefore, error prone. Static Analysis Analysis of code without actually executing the code Find useful info like: unused variables unhandled exceptions style errors statistics Linters are a subset of static analyzers Formal Verification Uses mathematical techniques to prove the correctness of a program Advantages over testing: Prove the absence of errors (testing can only prove the presence of errors, not their absence) Disadvantages: Only proves the compliance with the specification, but not the actual utility of the software Requires highly specialized notations and knowledge which makes it an expensive technique to administer (more commonly used in safety-critical software such as flight control systems) Test Case Design Postive test case : is designed to produce valid behaviour. Negative test case : is designed to produce an invalid behaviour. Black-box (aka specification-based or responsibility-based): test cases are designed exclusively based on the SUT's specified external behaviour. White-box (aka glass-box or structured or implementation-based): test cases are designed based on what is known about the SUT's implementation. Gray-box : mix of both Equivalence partitions (aka equivalence class): A group of test inputs that are likely to be processed by the SUT in the same way. Avoid testing too many inputs from one partition Ensure all partitions are tested Boundary value analysis (BVA) is a test case design heuristic that is based on the observation that bugs often result from incorrect handling of boundaries of equivalence partitions. Choose 3 values to test: below, in and above boundary Combining test inputs Testing all possible combinations is effective but not efficient Combination strategies: The all combinations strategy generates test cases for each unique combination of test inputs. The at least once strategy includes each test input at least once. The all pairs strategy creates test cases so that for any given pair of inputs, all combinations between them are tested. Heuristic: Each valid input at least once in a positive test case Heuristic: No more than one invalid input in a test case Testing Regression Testing Regression testing is the re-testing of the software to detect regressions. When you modify a system, the modification may result in some unintended and undesirable effects on the system. Such an effect is called a regression. Developer Testing Developer testing is the testing done by the developers themselves as opposed to dedicated testers or end-users. Early testing is better: earlier a bug is found, easier and cheaper to have it fixed. Unit Testing Unit testing is testing individual units (methods, classes, subsystems) to ensure each piece works correctly. Stubs: a stub has the same interface as the component it replaces, but its implementation is so simple that it is unlikely to have any bugs. Can isolate the SUT from its dependencies Typically these mimicked responses are hard-coded Integration Testing Integration testing is testing whether different parts of the software work together as expected. Not simply a case of repeating the unit test cases using the actual dependencies, but are additional test cases that focus on interactions between the parts. Pure unit/ integration testing has one extra step than hybrid Hybrid skips the steps that requires stubs System Testing System testing is testing that takes the whole system and tests it against the system specification. Based on specified external behaviour of the system Includes testing against non-functional requirements: Usability, portability, performance, security, load, compatibility testing Alpha and Beta Testing Alpha testing is performed by the users, under controlled conditions set by the software development team. Beta testing is performed by a selected subset of target users of the system in their natural work setting. Dogfooding Creators use their own product to test it. Exploratory and Scripted Testing Scripted testing: first write a set of test cases based on the expected behavior of the SUT, and then perform testing based on that set of test cases. Exploratory: Devise test cases on-the-fly, creating new test cases based on the results of the past test cases. Known as reactive testing, error guessing technique, attack-based testing and bug hunting User Acceptance Testing User acceptance testing is testing the system to ensure it meets the user requirements. System Testing Acceptance Testing Done against the system specifications Done against the requirements specification Done by testers of the project team Done by a team that represents the customer Done on the development environment or a test bed Done on the deploymet site or on a close simulation of the deployment site Both negative and positive test cases More focus on positive test cases Test Automation Testing An automated test case can be run programmatically and the result of the test case (pass or fail) is determined programmatically. Automated testing of CLI apps : A simple way to semi-automate testing of a CLI (Command Line Interface) app is by using input/output re-direction. Test automation using test drivers : JUnit is a tool for automated testing of Java programs. Automated testing of GUIs : testing tools like TestFX, Visual Studio, Selenium Test coverage : Test coverage is a metric used to measure the extent to which testing exercises the code. Function/ method coverage: based on functions executed e.g., testing executed 90 out of 100 functions. Statement coverage: based on the number of lines of code executed e.g., testing executed 23k out of 25k LOC. Decision/branch coverage: based on the decision points exercised e.g., an if statement evaluated to both true and false with separate test cases during testing is considered 'covered'. Condition coverage: based on the boolean sub-expressions, each evaluated to both true and false with different test cases. Condition coverage is not the same as the decision coverage. Path coverage: measures coverage in terms of possible paths through a given part of the code executed. 100% path coverage means all possible paths have been executed. A commonly used notation for path analysis is called the Control Flow Graph (CFG). Entry/exit coverage: measures coverage in terms of possible calls to and exits from the operations in the SUT. Entry points refer to all places from which the method is called from the rest of the code i.e., all places where the control is handed over to the method in concern. Exit points refer to points at which the control is returned to the caller e.g., return statements, throwing of exceptions. Dependency injection : Dependency injection is the process of 'injecting' objects to replace current dependencies with a different object. Often used to inject stubs to isolate the SUT from its dependencies so that it can be tested in isolation. Polymorphism can be used to implement dependency injection. Test-driven development (TDD) : Advocates writing the tests before writing the SUT, while evolving functionality and tests in small increments.","title":"CS2103/T Notes"},{"location":"cs2103t/cs2103t-notes/#cs2103t-notes","text":"CS2103/T Notes Java Varargs Programming Paradigm Object-Oriented Programming (OOP) Requirements Non-functional Requirements Quality of Requirements Gathering Requirements Specifying Requirements Design Design Fundamentals Modeling Design Patterns Singleton Pattern Abstraction Occurrence Pattern Facade Pattern Command Pattern Model View Controller (MVC) Pattern Observer Pattern Design Approaches Principles S ingle Responsibility Principle O pen-Closed Principle L iskov Substitution Principle I nterface Segregation Principle D ependency Inversion Principle Separation of Concerns Principle Law of Demeter YAGNI Principle DRY Principle Brooks' Law UML Class Diagrams Notation \u2014 Class Diagrams Associations \u2014 Class Diagrams Navigability Multiplicity Dependencies Composition (Has-A) Aggregation Inheritance (Is-A) Objects Diagrams Notation \u2014 Objects Diagrams Sequence Diagrams Notation \u2014 Sequence Diagrams OODM Activity Diagrams Notation \u2014 Activity Diagrams Project Management Revision Control Project Planning Work Breakdown Structure Milestones Buffers Issue Trackers GANTT Charts PERT Charts SDLC Process Models Sequential Models Iterative Models Agile Models XP Scrum Unified Process CMMI Coding Standards Naming Layout Statements Classes and interfaces Methods Types Variables Loops Conditionals Comments Implementation Coding Quality Refactoring Documentation Types Guidelines Error Handling Integration Reuse Quality Assurance Code Reviews Static Analysis Formal Verification Test Case Design Testing Regression Testing Developer Testing Unit Testing Integration Testing System Testing Alpha and Beta Testing Dogfooding Exploratory and Scripted Testing User Acceptance Testing Test Automation Testing","title":"CS2103/T Notes"},{"location":"cs2103t/cs2103t-notes/#java","text":"","title":"Java"},{"location":"cs2103t/cs2103t-notes/#varargs","text":"Syntactic sugar type feature that allows writing a method that can take a variable number of arguments. public static void search(String ... keywords){ // method body }","title":"Varargs"},{"location":"cs2103t/cs2103t-notes/#programming-paradigm","text":"Guides programmers to analyse programmig problems ad structure programmig solutions in a specific way","title":"Programming Paradigm"},{"location":"cs2103t/cs2103t-notes/#object-oriented-programming-oop","text":"Views the world as a network of interacting objects Tries to create a similar object network inside the computer's memory so that a similar result can be achieved programmtically","title":"Object-Oriented Programming (OOP)"},{"location":"cs2103t/cs2103t-notes/#requirements","text":"A software requirement specifies a need to be fulfilled by the software product. A software project may be Brownfield project i.e., develop a product to replace/update an existing software product Greenfield project i.e., develop a totally new system from scratch Requirements come from stakeholders Requirements can be divided into: Functional requirements specify what the system should do Non-functional requirements specify the constraints under which the system is developed and operated","title":"Requirements"},{"location":"cs2103t/cs2103t-notes/#non-functional-requirements","text":"Specify the constraints under which the system is developed and operated NFRs are easier to miss Sometimes NFRs are critical to the success of the software","title":"Non-functional Requirements"},{"location":"cs2103t/cs2103t-notes/#quality-of-requirements","text":"Characteristics of well-defined requirements: Unambiguous Testable (verifiable) Clear (concise, terse, simple, precise) Correct Understandable Feasible (realistic, possible) Independent Atomic Necessary Implementation-free (i.e. abstract) Set of requirements as a whole should be: Consistent Non-redundant Complete","title":"Quality of Requirements"},{"location":"cs2103t/cs2103t-notes/#gathering-requirements","text":"Brainstorming session No \"bad\" ideas (aim is to generate ideas; not to validate them) Product surveys Studying existing products can unearth shortcomings of existing solutions that can be addressed by a new product Observation Observing users in their natural work environment can uncover product requirements User surveys Surveys can be used to solicit responses and opinions from a large number of stakeholders regarding a current product or a new product Interviews Interviewing stakeholders and domain experts can produce useful information about project requirements Focus groups Focus groups are a kind of informal interview within an interactive group setting Prototyping A prototype is a mock up, a scaled down version, or a partial system constructed to get users feedback to validate a technical concept (a \"proof-of-concept\" prototype) to give a preview of what is to come, or to compare multiple alternatives on a small scale before committing fully to one alternative for early field-testing under controlled conditions","title":"Gathering Requirements"},{"location":"cs2103t/cs2103t-notes/#specifying-requirements","text":"Feature list A list of features of a product grouped according to some criteria such as aspect, priority, order of delivery, etc User stories Short, simple descriptions of a feature told from the perspective of the person who desires the new capability, usually a user or customer of the system Format: As a {user type/role} I can {function} so that {benefit} {benefit} can be omitted if it is obvious Can: Add more characteristics to the {user role} , e.g. As a forgetful user, ... Write user stories at various levels (epic/theme) Add conditions of satisfaction to a user story Include: Priority: how important the user story is Size: the estimated effort to implement the user story Urgency: how soon the feature is needed Convenient for scoping, estimation, and scheduling Less details compared to traditional requirements specifications Captures non-functional requirements too because even NFRs must benefit some stakeholder Handy for recording requirements during early stages of requirements gathering Use cases Set of sequences of actions, including variants, that a system performs to yield an observable result of value to an actor Describes an interaction between the user and the system for a specific functionality of the system Only externally visible behavior (omit UI details) Actor : An actor (in a use case) is a role played by a user. can be a human or another system. not part of the system; they reside outside the system. Main Success Scenario (MSS) describes the most straightforward interaction for a given use case, which assumes that nothing goes wrong Extensions are \"add-on\"s to the MSS that describe exceptional/alternative flow of events Glossary Serves to ensure that all stakeholders have a common understanding of the noteworthy terms, abbreviations, acronyms etc Supplementary requirements This section can be used to capture requirements that do not fit elsewhere Typically, this is where most Non-Functional Requirements will be listed","title":"Specifying Requirements"},{"location":"cs2103t/cs2103t-notes/#design","text":"","title":"Design"},{"location":"cs2103t/cs2103t-notes/#design-fundamentals","text":"Abstraction Data abstraction: abstracting away the lower level data items and thinking in terms of bigger entities Control abstraction: abstracting away details of the actual control flow to focus on tasks at a higher level Coupling Coupling is a measure of the degree of dependence between components, classes, methods, etc. Low coupling indicates that a component is less dependent on other components High coupling is discouraged: maintenance, integration, testing and reuse of module is harder. Zero coupling is not possible for non-trivial software. Types: content, common/ global, data, external, subclass, temporal","title":"Design Fundamentals"},{"location":"cs2103t/cs2103t-notes/#modeling","text":"A model provides a simpler view of a complex entity because a model captures only a selected aspect. This omission of some aspects implies models are abstractions. Multiple models of the same entity may be needed to capture it fully. Models can be used as a blueprint for creating software.","title":"Modeling"},{"location":"cs2103t/cs2103t-notes/#design-patterns","text":"An elegant reusable solution to a commonly recurring problem within a given context in software design Common format to describe a pattern: Context: The situation or scenario where the design problem is encountered Problem: The main difficulty to be resolved Solution: The core of the solution. It is important to note that the solution presented only includes the most general details, which may need further refinement for a specific context Anti-patterns (optional): Commonly used solutions, which are usually incorrect and/or inferior to the Design Pattern. Consequences (optional): Identifying the pros and cons of applying the pattern Other useful information (optional): Code examples, known uses, other related patterns, etc 23 Design Patterns divided into 3 categories: Creational: About object creation. They separate the operation of an application from how its objects are created. Abstract Factory, Builder, Factory Method, Prototype, Singleton Structural: About the composition of objects into larger structures while catering for future extension in structure. Adapter, Bridge, Composite, Decorator, Facade , Flyweight, Proxy Behavioral: Defining how objects interact and how responsibility is distributed among them. Chain of Responsibility, Command , Interpreter, Template Method, Iterator, Mediator, Memento, Observer , State, Strategy, Visitor","title":"Design Patterns"},{"location":"cs2103t/cs2103t-notes/#singleton-pattern","text":"When to use: Requires only one instance of a class There is a risk of creating multiple objects by mistake Creating such multiple objects has real negative consequences How to use: Private constructor with a public class-level method to access the single instance Optional <<Singleton>> UML stereotype to indicate role Pros: Easy to apply Effective in achieving its goal with minimal extra work Provides an easy way to access the singleton object from anywhere in the code base Cons: Acts like a global variable that increases coupling across the code base In testing, its difficult to replace Singleton objects with stubs (static methods cannot be overridden). In testing, singleton objects carry data from one test to another","title":"Singleton Pattern"},{"location":"cs2103t/cs2103t-notes/#abstraction-occurrence-pattern","text":"When to use: Group of similar entities with common information Also differing in significant ways How to use: Split entity into 2 classes 1 object for common information ( Abstraction ) and many for unique information ( Occurrence )","title":"Abstraction Occurrence Pattern"},{"location":"cs2103t/cs2103t-notes/#facade-pattern","text":"When to use: Components need to access functionality deep inside other components. How to use: Create a Facade class that sits between users of component and component internals All access to the component happens through the Facade class","title":"Facade Pattern"},{"location":"cs2103t/cs2103t-notes/#command-pattern","text":"When to use: Have a system is required to execute a number of commands Each doing a different task How to use: Create a general Command object such that it can be used without knowing the exact type of command (using polymorphism) Example: Command interface in AB3 where all Commands implement this interface and have an execute method","title":"Command Pattern"},{"location":"cs2103t/cs2103t-notes/#model-view-controller-mvc-pattern","text":"When to use: Support storage/retrieval of information Displaying of information to the user (often via multiple UIs having different formats) Changing stored information based on external inputs How to use: Split the data, presentation and control logic into 3 parts: View: Displays data, interacts with the user, and pulls data from the model if necessary. Controller: Detects UI events such as mouse clicks and button pushes, and takes follow up action. Updates/changes the model/view when necessary. Model: Stores and maintains data. Updates the view if necessary. In a simple UI where there is only one view, Controller and View can be combined as one class.","title":"Model View Controller (MVC) Pattern"},{"location":"cs2103t/cs2103t-notes/#observer-pattern","text":"When to use: An object (possibly more than one) needs to be notified when a change happens to another object How to use: Force the communication through an interface known to both parties Have all observers implement an Observer interface Add all observers to the observee's observer list When there is an update, notify all added observers","title":"Observer Pattern"},{"location":"cs2103t/cs2103t-notes/#design-approaches","text":"Top-down: Design the high-level design first and flesh out the lower levels later Useful when designing big and novel systems where the high-level design needs to be stable before lower levels can be designed Bottom-up: Design lower level components first and put them together to create the higher-level systems later. Not usually scalable for bigger systems. One instance where this approach might work is when designing a variation of an existing system or re-purposing existing components to build a new system Mix: Design the top levels using the top-down approach but switch to a bottom-up approach when designing the bottom levels Agile: Emergent and not defined up front Overall system design will emerge over time, evolving to fulfill new requirements and take advantage of new technologies as appropriate Just enough initial architectural modeling at the very beginning of a project to get your team going Does not produce a fully documented set of models in place before you may begin coding","title":"Design Approaches"},{"location":"cs2103t/cs2103t-notes/#principles","text":"","title":"Principles"},{"location":"cs2103t/cs2103t-notes/#single-responsibility-principle","text":"Definition: A class should have one, and only one, reason to change If a class has only one responsibility, it needs to change only when there is a change to that responsibility Good way of identifying classes during the design phase","title":"Single Responsibility Principle"},{"location":"cs2103t/cs2103t-notes/#open-closed-principle","text":"Definition: A module should be open for extension but closed for modification. That is, modules should be written so that they can be extended, without requiring them to be modified Aims to make a code entity easy to adapt and reuse without needing to modify the code entity itself Separating the specification (i.e. interface) of a module from its implementation","title":"Open-Closed Principle"},{"location":"cs2103t/cs2103t-notes/#liskov-substitution-principle","text":"Definition: Derived classes must be substitutable for their base classes Subclass should not be more restrictive than the behavior specified by the superclass LSP is not followed when substituting a subclass object for a superclass object breaks the functionality of the code","title":"Liskov Substitution Principle"},{"location":"cs2103t/cs2103t-notes/#interface-segregation-principle","text":"Definition: No client should be forced to depend on methods it does not use Can depend on an interface with just the methods it need, instead of the entire class","title":"Interface Segregation Principle"},{"location":"cs2103t/cs2103t-notes/#dependency-inversion-principle","text":"Definition: High-level modules should not depend on low-level modules. Both should depend on abstractions Abstractions should not depend on details. Details should depend on abstractions","title":"Dependency Inversion Principle"},{"location":"cs2103t/cs2103t-notes/#separation-of-concerns-principle","text":"Definition: To achieve better modularity, separate the code into distinct sections, such that each section addresses a separate concern A concern is a set of information that affects the code of a computer program Reduces functional overlaps Limits ripple effect when changes are introduced to a specific part of system Can be applied at the class level as well as higher levels Lead to higher cohesion and lower coupling","title":"Separation of Concerns Principle"},{"location":"cs2103t/cs2103t-notes/#law-of-demeter","text":"Definition: An object should have limited knowledge of another object An object should only interact with objects that are closely related to it Aims to prevent objects from navigating the internal structures of other objects Method foo of an object obj should invoke only the methods of the following kinds of objects: Object obj itself Objects passed as parameters of foo Objects created/instantiated in foo (directly or indirectly) Objects from the direct association of obj","title":"Law of Demeter"},{"location":"cs2103t/cs2103t-notes/#yagni-principle","text":"Definition: You Aren't Gonna Need It! Do not add code simply because 'you might need it in the future' Some capability you presume your software needs in the future should not be built now Do not have perfect information about the future The extra work might go to waste when some of your predictions fail to materialize","title":"YAGNI Principle"},{"location":"cs2103t/cs2103t-notes/#dry-principle","text":"Definition: Don't Repeat Yourself Every piece of knowledge must have a single, unambiguous, authoritative representation within a system Guards against the duplication of information Examples of violations: Functionality being implemented twice even if the two implementations are different Value of a system-wide timeout being defined in multiple places","title":"DRY Principle"},{"location":"cs2103t/cs2103t-notes/#brooks-law","text":"Definition: Adding people to a late project will make it later The additional communication overhead will outweigh the benefit of adding extra manpower, especially if done near a deadline","title":"Brooks' Law"},{"location":"cs2103t/cs2103t-notes/#uml","text":"","title":"UML"},{"location":"cs2103t/cs2103t-notes/#class-diagrams","text":"Used to model class structures of an OO solution Describe the structure (but not behaviour) of OOP solution","title":"Class Diagrams"},{"location":"cs2103t/cs2103t-notes/#notation-class-diagrams","text":"Visibility: + for public | - for private | # for protected | ~ package private (default) Class-level methods/ attributes are underlined <<interface>> <<enumeration>> {abstract} or abstract OK to omit: Methods","title":"Notation \u2014 Class Diagrams"},{"location":"cs2103t/cs2103t-notes/#associations-class-diagrams","text":"Association roles appears on end that plays that role An association can be shown as a line between the two classes or as an attribute in one of the classes (but not both).","title":"Associations \u2014 Class Diagrams"},{"location":"cs2103t/cs2103t-notes/#navigability","text":"Solid arrow The concept of which object in the association knows about the other object. E.g. Navigability is from Box to Rope , b will have reference to r but not vice versa. One can navigate from b to r using b 's object reference of r .","title":"Navigability"},{"location":"cs2103t/cs2103t-notes/#multiplicity","text":"0..X Number of X is on end nearer X. The aspect of an OOP solution that dictates how many objects take part in each association.","title":"Multiplicity"},{"location":"cs2103t/cs2103t-notes/#dependencies","text":"Dotted line A need for one class to depend on another without having a direct association in the same direction.","title":"Dependencies"},{"location":"cs2103t/cs2103t-notes/#composition-has-a","text":"Shaded diamond Diamond is on the end of the whole. A composition is an association that represents a strong whole-part relationship. When the whole is destroyed, parts are destroyed too (parts cannot exist without whole). Cannot be cyclical links.","title":"Composition (Has-A)"},{"location":"cs2103t/cs2103t-notes/#aggregation","text":"Non-shaded/hollow diamond Diamond is on the end of the container. An aggregation is an association that represents a container-contained relationship. Similar to that of composition except the containee object can exist even after the container object is deleted. Weaker relationship than composition. Aggregation represents a container-contained relationship. It is a weaker relationship than composition.","title":"Aggregation"},{"location":"cs2103t/cs2103t-notes/#inheritance-is-a","text":"Triangle arrow (inheriting class - class or interface - interface) Triangle arrow with dotted line: implementing an interface Does not matter whether the triangle is filled or empty Points to parent class Inheritance implies the derived class can be considered as a sub-type of the base class (and the base class is a super-type of the derived class), resulting in an is a relationship.","title":"Inheritance (Is-A)"},{"location":"cs2103t/cs2103t-notes/#objects-diagrams","text":"Used to model object structure of an OO solution Multiple object diagrams can correspond to a single class diagram","title":"Objects Diagrams"},{"location":"cs2103t/cs2103t-notes/#notation-objects-diagrams","text":"Object names are underlined If there is inheritance, show either parent class or child class (not both) MUST omit: Methods Multiplicities OK to omit: Object name Variable name/ value Attributes compartment (if not relevant) Association labels/ roles (if not relevant)","title":"Notation \u2014 Objects Diagrams"},{"location":"cs2103t/cs2103t-notes/#sequence-diagrams","text":"","title":"Sequence Diagrams"},{"location":"cs2103t/cs2103t-notes/#notation-sequence-diagrams","text":"Arrows representing method calls: solid lined arrows Arrows representing method returns: dashed lined arrows Class/object name is not underlined Use an X at the end of the lifeline of an object to show its deletion Self-invocation calls is denoated by an arrow from the bar to itself Method calls to static methods are received by the class itself You can use <<class>> to show that a participant is the class itself All frames should use a rectangle with a clip on the bottom-right corner loop frame: indicate a loop (can execute 0 times) loop [condition] alt frame: indicate alternative paths alt [condition] No more than one alternative partitions be executed in an alt frame opt frame: indicate optional paths opt [condition] ref frame: allow a segment of the interaction to be omitted and shown as a separate sequence diagram ref diagram title (in the original diagram) sd diagram title (sub-sequence diagram shown in this frame) par frame: indicate parallel paths (can happen in any order) The corresponding Java implementation is likely to be multi-threaded- Keywords are loop (while), opt (if) and alt (if elseif) OK to omit: Activation bar Return arrows Activation bar of self-invocation","title":"Notation \u2014 Sequence Diagrams"},{"location":"cs2103t/cs2103t-notes/#oodm","text":"Similar to class diagram notation but must omit: methods navigability Do not contain solution-specific classes (classes that do not exist in the problem domain e.g. DatabaseConnection)","title":"OODM"},{"location":"cs2103t/cs2103t-notes/#activity-diagrams","text":"Models workflows","title":"Activity Diagrams"},{"location":"cs2103t/cs2103t-notes/#notation-activity-diagrams","text":"Action : rounded corners rectangle Denotes a single step in an activity. Control flow : arrow-head line Denotes the flow of control from one action to the next. Start node : shaded circle Denotes the start of the activity End node : inner shaded circle with with a surrounding circle Denotes the end of the activity Branch node : diamond square with two [conditions] Denotes the start of alternate path. Exactly one of the guard conditions should be true. Merge node : diamond square Denotes the end of alternative paths Fork node : bar Denotes the start of concurrent flows of cotntrol. Join node : bar Denotes the end of parallel paths Rake : rake symbol Denotes that the action is described in another subsidiary activity diagram Swim lanes : partition Denotes who is doing which action (also called swimlane diagrams) OK to do: Multiple arrows can start from the same corner of a branch node Omit merge node if it there's no ambiguity Omit [Else] condition.","title":"Notation \u2014 Activity Diagrams"},{"location":"cs2103t/cs2103t-notes/#project-management","text":"","title":"Project Management"},{"location":"cs2103t/cs2103t-notes/#revision-control","text":"Process of managing multiple versions of a piece of information Will track the history and evolution of your project Makes it easier for to collaborate Repository is the database that stores the revision history. Using History Tag a specific commit to identify To see what changed: diff To restore the state of the working directory at point in the past: checkout the commit Remote Repositories git clone a repo to create a (local) copy Original repo is referred to as upstream repo git pull from one repo to another git push new commits in one repo to another Fork is a remote copy of a remote repo Pull request is a mechanism for contributing code to a remote repo Branching is the process of evolving multiple versions of the software in parallel. Merge conflicts happen when you try to merge two branches that had changed the same part of the code and the revision control software (RCS) cannot decide which changes to keep. Centralized RCS uses a central remote repo that is shared by the team. Distributed RCS allows multiple remote repos and pulling and pushing can be done among them in arbitrary ways. Forking flow : the 'official' version of the software is kept in a remote repo designated as the 'main repo'. All team members fork the main repo and create pull requests from their fork to the main repo. Feature branch workflow is similar to forking workflow except there are no forks. Centralized flow is similar to the feature branch workflow except all changes are done in the master branch.","title":"Revision Control"},{"location":"cs2103t/cs2103t-notes/#project-planning","text":"","title":"Project Planning"},{"location":"cs2103t/cs2103t-notes/#work-breakdown-structure","text":"Depicts information about tasks and their details in terms of subtasks Can also include prerequisite tasks and effort estimates for each task Effort is traditionally measured in man hour/day/month All tasks should be well-defined Task ID Task Estimated Effort Prerequisite Task A Analysis 1 man hour - B Design 2 man day A","title":"Work Breakdown Structure"},{"location":"cs2103t/cs2103t-notes/#milestones","text":"End of a stage which indicates significant progress Should account for dependencies and priorities when deciding on the features to be delivered at a certain milestone Each intermediate product release is a milestone","title":"Milestones"},{"location":"cs2103t/cs2103t-notes/#buffers","text":"Time set aside to absorb unforeseen delays Very important to include because effort/time estimations are notoriously hard Do not inflate task estimates to create hidden buffers (have explicit buffers instead) Reason: With explicit buffers, it is easier to detect incorrect effort estimates which can serve as feedback to improve future estimates","title":"Buffers"},{"location":"cs2103t/cs2103t-notes/#issue-trackers","text":"Issue trackers (sometimes called bug trackers) are commonly used to track task assignment and progress","title":"Issue Trackers"},{"location":"cs2103t/cs2103t-notes/#gantt-charts","text":"2-D bar-chart Drawn as time vs tasks Solid bar represents the main task (composed of a number of subtasks) Grey bars represent subtasks Diamond shape indicates an important deadline/deliverable/milestone","title":"GANTT Charts"},{"location":"cs2103t/cs2103t-notes/#pert-charts","text":"Program Evaluation Review Technique Shows the order/sequence of tasks Directed graph: Nodes or vertices capture the effort estimations of tasks Arrows depict the precedence between tasks Helps determine the following: Order of tasks Which tasks can be done concurrently Shortest possible completion time Critical path (path where any delay can directly affect the project duration, hence it is important to ensure tasks on the critical path are completed on time)","title":"PERT Charts"},{"location":"cs2103t/cs2103t-notes/#sdlc-process-models","text":"Software development goes through different stages such as requirements, analysis, design, implementation and testing Collectively known as the software development life cycle (SDLC)","title":"SDLC Process Models"},{"location":"cs2103t/cs2103t-notes/#sequential-models","text":"Views software development as a linear process Also called waterfall model When one stage of the process is completed, it produces some artifacts to be used in the next stage A strict sequential model project moves only in the forward direction Pros: Work well for a project that produces software to solve a well-understood problem Cons: Real-world projects often tackle problems that are not well-understood at the beginning","title":"Sequential Models"},{"location":"cs2103t/cs2103t-notes/#iterative-models","text":"Advocates producing the software by going through several iterations Each iteration produces a new version of the product that builds on the version produced in previous iteration Breadth-first An iteration evolves all major components and all functionality areas in parallel Depth-first An iteration focuses on fleshing out only some components or some functionality area. Early depth-first iterations might not produce a working product. A project can be done as a mixture of breadth-first and depth-first iterations","title":"Iterative Models"},{"location":"cs2103t/cs2103t-notes/#agile-models","text":"","title":"Agile Models"},{"location":"cs2103t/cs2103t-notes/#xp","text":"Extreme programming Stresses customer satisfaction Aims to make developers confidently respond to changing requirements (even late in life cycle) Emphasizes teamwork Improve in: communication, simplicity, feedback, respect and courage Has a set of simple rules","title":"XP"},{"location":"cs2103t/cs2103t-notes/#scrum","text":"Scrum is a process skeleton that contains sets of practices and predefined roles. The main roles in Scrum are: The Scrum Master , who maintains the processes (typically in lieu of a project manager). The Product Owner , who represents the stakeholders and the business. The Team, a cross-functional group who do the actual analysis, design, implementation, testing, etc. A Scrum project is divided into iterations called Sprints . A key principle of Scrum is its recognition that during a project the customers can change their minds about what they want and need. The daily scrum meeting is not used as a problem-solving or issue resolution meeting. Issues that are raised are taken offline and usually dealt with by the relevant subgroup immediately after the meeting. Members answer these questions What did you do yesterday? What will you do today? Are there any impediments in your way?","title":"Scrum"},{"location":"cs2103t/cs2103t-notes/#unified-process","text":"Flexible and customizable process model framework Consists of four phases: inception, elaboration, construction and transition Phase Activities Typical Artifacts Inception Understand the problem and requirements Communicate with customer Plan the development effort Basic use case model Rough project plan Project vision and scope Elaboration Refine and expand requirements Determine a high-level design System architecture Various design models Prototype Construction Major implementation effort to support the use cases identified Design models are refined and fleshed out Testing of all levels are carried out Multiple releases of the system Test cases of all levels System release Transition Ready the system for actual production use Familiarize end users with the system Final system release Instruction manual","title":"Unified Process"},{"location":"cs2103t/cs2103t-notes/#cmmi","text":"Capability Maturity Model Integration Defines 5 maturity levels for a process (specifies criteria): Level 1: Initial Processes unpredictable, poorly controlled and reactive Level 2: Managed Processes characterised for projects and is often reactive Level 3: Defined Processes characterised for organisations and is proactive Level 4: Quantitatively Managed Processes measured and controlled Level 5: Optimizing Focus on process improvement","title":"CMMI"},{"location":"cs2103t/cs2103t-notes/#coding-standards","text":"","title":"Coding Standards"},{"location":"cs2103t/cs2103t-notes/#naming","text":"Names representing packages should be in all lower case. Class/ enum names must be nouns and written in PascalCase. Variable names must be in camelCase. Constant names must be in SCREAMING_SNAKE_CASE. Names representing methods must be verbs and written in camelCase. Abbreviation and acronyms should not be uppsercase when used as part of a name. All names should be written in English. Variables with a large scope should have long names, variables with a small scope can have short names. Boolean variables/ methods should be named to sound like booleans. Plural form should be used on names representing a collection of objects. Iterator variables can be called i, j, k. Associated constants should have a common prefix.","title":"Naming"},{"location":"cs2103t/cs2103t-notes/#layout","text":"Basic indentation should be 4 spaces. Line length should be no longer than 120 characters. Place line break to improve readability. Use egyptian style brackets. Method definitions should have the following form: public void someMethod() throws SomeException { ... } if-else class of statements should have the following form: if (condition) { statements; } for statement should have the following form: for (initialization; condition; update) { statements; } while statement should have the following form: while (condition) { statements; } switch statement should have the following form: switch (condition) { case ABC: statements; //Fallthrough case DEF: statements; break; } try-catch statement should have the following form: try { statements; } catch (Exception exception) { statements; } White space within a statement Operators should be surrounded by a space character Java reserved words should be followed by a white space Commas should be followed by a white space Colons should be surrounded by white space when used as binary/ ternary operator Logical units within a block should be separated by one blank line","title":"Layout"},{"location":"cs2103t/cs2103t-notes/#statements","text":"Put every class in a package Put related classes in a single package The ordering of import statements must be consistent Imported classes should always be listed explicity (not *)","title":"Statements"},{"location":"cs2103t/cs2103t-notes/#classes-and-interfaces","text":"Class/Interface documentation (Comments) class or interface statement Class (static) variables in the order public, protected, package (no access modifier), private Instance variables in the order public, protected, package (no access modifier), private Constructors Methods (no specific order)","title":"Classes and interfaces"},{"location":"cs2103t/cs2103t-notes/#methods","text":"Method modifiers should be given in the following order: <access> static abstract synchronized <unusual> final native","title":"Methods"},{"location":"cs2103t/cs2103t-notes/#types","text":"Array specifiers must be attached to the type not the variable int[] a = new int[20];","title":"Types"},{"location":"cs2103t/cs2103t-notes/#variables","text":"Variables should be initialized where they are declared and they should be declared in the smallest scope possible. Class variables should never be declared public. Avoid unnecessary use of this with fields.","title":"Variables"},{"location":"cs2103t/cs2103t-notes/#loops","text":"Loop body should be wrapped by curly brackets irrespective of how many lines there are in the body.","title":"Loops"},{"location":"cs2103t/cs2103t-notes/#conditionals","text":"Conditional should be put on a separate line. Single statement conditionals should still be wrapped by curly brackets.","title":"Conditionals"},{"location":"cs2103t/cs2103t-notes/#comments","text":"All comments should be written in English. Write descriptive header comments for all public classes/ methods. All non-trivial private methods should carry header comments. Javadoc comments should have the following form: /** * Returns lateral location of the specified position. * If the position is unset, NaN is returned. * * @param x X coordinate of position. * @param y Y coordinate of position. * @param zone Zone of position. * @return Lateral location. * @throws IllegalArgumentException If zone is <= 0. */ public double computeLocation(double x, double y, int zone) throws IllegalArgumentException { //... } Comments should be indented relative to their position in the code. while (true) { // Do something something(); }","title":"Comments"},{"location":"cs2103t/cs2103t-notes/#implementation","text":"","title":"Implementation"},{"location":"cs2103t/cs2103t-notes/#coding-quality","text":"Avoid long methods Avoid deep nesting Avoid complicated expressions Avoid magic numbers Make the code obvious Structure code logically Do not 'trip up' reader Avoid unused paramters in method signature Similar things that look different Different things that look similar Multiple statements in the same line Practice KISSing Keep it simple, stupid Do not try to write 'clever' code Avoid premature optimizations SLAP hard Single Level of Abstraction Principle Avoid having multiple levels of abstraction within a code fragment Make the happy path prominent Naming: Use nouns for things and verbs for actions Use standard words Use name to explain Not too long, not too short Avoid misleading names","title":"Coding Quality"},{"location":"cs2103t/cs2103t-notes/#refactoring","text":"The process of improving a program's internal structure in small steps without modifying its external behavior is called refactoring Refactoring is not rewriting and not bug fixing (alters external behaviour). Benefits: hidden bugs become easier to spot improve performance Refactoring can result in regression Consolidate Duplicate Conditional Fragments // BEFORE if (isSpecialDeal()) { total = price * 0.95; send(); } else { total = price * 0.98; send(); } // AFTER if (isSpecialDeal()) { total = price * 0.95; } else { total = price * 0.98; } send(); Extract Method (opposite of this is inline method) from: //BEFORE void printOwing() { printBanner(); // print details System.out.println(\"name: \" + name); System.out.println(\"amount \" + getOutstanding()); } //AFTER void printOwing() { printBanner(); printDetails(getOutstanding()); } void printDetails(double outstanding) { System.out.println(\"name: \" + name); System.out.println(\"amount \" + outstanding); }","title":"Refactoring"},{"location":"cs2103t/cs2103t-notes/#documentation","text":"Developer-as-user: API documentaion or tutorial-style instructional documentation Developer-as-maintainer: how a system or component is designed implemented and tested","title":"Documentation"},{"location":"cs2103t/cs2103t-notes/#types_1","text":"Tutorials (learning-oriented) How-to guides (goal-oriented) Explanation (understanding-oriented) Reference (information-oriented)","title":"Types"},{"location":"cs2103t/cs2103t-notes/#guidelines","text":"Top-down, not bottom-up The reader can travel down a path she is interested in until she reaches the component she is interested to learn in-depth Comprehensibility Use plenty of diagrams, examples, simple and direct explanations Document minimally but sufficiently 'just enough' developer documentation","title":"Guidelines"},{"location":"cs2103t/cs2103t-notes/#error-handling","text":"Exceptions are used to deal with 'unusual' but not entirely unexpected situations that the program might encounter at runtime. After a method throws an exception, the runtime system attempts to find something to handle it in the call stack. Assertions are used to define assumptions about the program state so that the runtime can verify them. Assertions can be disabled without modifying the code. Java disables assertions by default. Assertions are used to define assumptions about the program state so that the runtime can verify them. Recommended that assertions be used liberally in the code. assertEquals is a JUnit method and only used in test classes. Logging is the deliberate recording of certain information during a program execution for future reference. Defensive programming is proactively eliminating any room for things to go wrong. Enforcing compulsory associations Enforcing 1-to-1 association Enforcing referential integrity (prevents case where A says B is X but B says B is Y) Design-by-contract approach is an approach for designing software that requires defining formal, precise and verifiable interface specifications for software components. Code first checks if the preconditions have been met.","title":"Error Handling"},{"location":"cs2103t/cs2103t-notes/#integration","text":"Timing and frequency: Late and One Time : wait till all components are completed and integrate all finished components near the end of the project Not reccommended because integration often causes many component incompatibilities which can lead to delivery delays Early and Frequent : integrate early and evolve each part in parallel, in small steps, re-integrating frequently Extent: Big-bang integration : integrate all components at the same time Not reccommended because it will uncover too many problems at the same time Incremental integration : integrate a few components at a time (integration problems surface in a more manageable way) Direction: Top-down integration : higher-level components are integrated before bringing in the lower-level components +: Higher-level problems can be discovered early -: Requires the use of stubs in place of lower level components Bottom-up integration : the reverse of top-down integration When integrating lower level components, drivers may be needed to test the integrated components, because UI may not be integrated yet Sandwich integration : a mix of top-down and bottom-up approaches, do both and meet in the middle","title":"Integration"},{"location":"cs2103t/cs2103t-notes/#reuse","text":"API : An Application Programming Interface (API) specifies the interface through which other programs can interact with a software component. It is a contract between the component and its clients. Library : A library is a collection of modular code that is general and can be used by other programs. Frameworks : A software framework is a reusable implementation of a software (or part thereof) providing generic functionality that can be selectively customized to produce a specific application. Some frameworks provide a complete implementation of a default behavior which makes them immediately usable. (e.g. Eclipse) Platforms : A platform provides a runtime environment for applications. Cloud computing : Cloud computing is the delivery of computing as a service over the network, rather than a product running on a local machine. Infrastructure as a service (IaaS) delivers computer infrastructure as a service. Platform as a service (PaaS) provides a platform on which developers can build applications. Software as a service (SaaS) allows applications to be accessed over the network instead of installing them on a local machine.","title":"Reuse"},{"location":"cs2103t/cs2103t-notes/#quality-assurance","text":"Quality Assurance = Validation + Verification","title":"Quality Assurance"},{"location":"cs2103t/cs2103t-notes/#code-reviews","text":"Systematic examination of code with the intention of finding where the code can be improved Three types covered: PR reviews In pair programming Formal inspections Advantages over testing: It can detect functionality defects as well as other problems such as coding standard violations. It can verify non-code artifacts and incomplete code. It does not require test drivers or stubs. Disadvantages: It is a manual process and therefore, error prone.","title":"Code Reviews"},{"location":"cs2103t/cs2103t-notes/#static-analysis","text":"Analysis of code without actually executing the code Find useful info like: unused variables unhandled exceptions style errors statistics Linters are a subset of static analyzers","title":"Static Analysis"},{"location":"cs2103t/cs2103t-notes/#formal-verification","text":"Uses mathematical techniques to prove the correctness of a program Advantages over testing: Prove the absence of errors (testing can only prove the presence of errors, not their absence) Disadvantages: Only proves the compliance with the specification, but not the actual utility of the software Requires highly specialized notations and knowledge which makes it an expensive technique to administer (more commonly used in safety-critical software such as flight control systems)","title":"Formal Verification"},{"location":"cs2103t/cs2103t-notes/#test-case-design","text":"Postive test case : is designed to produce valid behaviour. Negative test case : is designed to produce an invalid behaviour. Black-box (aka specification-based or responsibility-based): test cases are designed exclusively based on the SUT's specified external behaviour. White-box (aka glass-box or structured or implementation-based): test cases are designed based on what is known about the SUT's implementation. Gray-box : mix of both Equivalence partitions (aka equivalence class): A group of test inputs that are likely to be processed by the SUT in the same way. Avoid testing too many inputs from one partition Ensure all partitions are tested Boundary value analysis (BVA) is a test case design heuristic that is based on the observation that bugs often result from incorrect handling of boundaries of equivalence partitions. Choose 3 values to test: below, in and above boundary Combining test inputs Testing all possible combinations is effective but not efficient Combination strategies: The all combinations strategy generates test cases for each unique combination of test inputs. The at least once strategy includes each test input at least once. The all pairs strategy creates test cases so that for any given pair of inputs, all combinations between them are tested. Heuristic: Each valid input at least once in a positive test case Heuristic: No more than one invalid input in a test case","title":"Test Case Design"},{"location":"cs2103t/cs2103t-notes/#testing","text":"","title":"Testing"},{"location":"cs2103t/cs2103t-notes/#regression-testing","text":"Regression testing is the re-testing of the software to detect regressions. When you modify a system, the modification may result in some unintended and undesirable effects on the system. Such an effect is called a regression.","title":"Regression Testing"},{"location":"cs2103t/cs2103t-notes/#developer-testing","text":"Developer testing is the testing done by the developers themselves as opposed to dedicated testers or end-users. Early testing is better: earlier a bug is found, easier and cheaper to have it fixed.","title":"Developer Testing"},{"location":"cs2103t/cs2103t-notes/#unit-testing","text":"Unit testing is testing individual units (methods, classes, subsystems) to ensure each piece works correctly. Stubs: a stub has the same interface as the component it replaces, but its implementation is so simple that it is unlikely to have any bugs. Can isolate the SUT from its dependencies Typically these mimicked responses are hard-coded","title":"Unit Testing"},{"location":"cs2103t/cs2103t-notes/#integration-testing","text":"Integration testing is testing whether different parts of the software work together as expected. Not simply a case of repeating the unit test cases using the actual dependencies, but are additional test cases that focus on interactions between the parts. Pure unit/ integration testing has one extra step than hybrid Hybrid skips the steps that requires stubs","title":"Integration Testing"},{"location":"cs2103t/cs2103t-notes/#system-testing","text":"System testing is testing that takes the whole system and tests it against the system specification. Based on specified external behaviour of the system Includes testing against non-functional requirements: Usability, portability, performance, security, load, compatibility testing","title":"System Testing"},{"location":"cs2103t/cs2103t-notes/#alpha-and-beta-testing","text":"Alpha testing is performed by the users, under controlled conditions set by the software development team. Beta testing is performed by a selected subset of target users of the system in their natural work setting.","title":"Alpha and Beta Testing"},{"location":"cs2103t/cs2103t-notes/#dogfooding","text":"Creators use their own product to test it.","title":"Dogfooding"},{"location":"cs2103t/cs2103t-notes/#exploratory-and-scripted-testing","text":"Scripted testing: first write a set of test cases based on the expected behavior of the SUT, and then perform testing based on that set of test cases. Exploratory: Devise test cases on-the-fly, creating new test cases based on the results of the past test cases. Known as reactive testing, error guessing technique, attack-based testing and bug hunting","title":"Exploratory and Scripted Testing"},{"location":"cs2103t/cs2103t-notes/#user-acceptance-testing","text":"User acceptance testing is testing the system to ensure it meets the user requirements. System Testing Acceptance Testing Done against the system specifications Done against the requirements specification Done by testers of the project team Done by a team that represents the customer Done on the development environment or a test bed Done on the deploymet site or on a close simulation of the deployment site Both negative and positive test cases More focus on positive test cases","title":"User Acceptance Testing"},{"location":"cs2103t/cs2103t-notes/#test-automation-testing","text":"An automated test case can be run programmatically and the result of the test case (pass or fail) is determined programmatically. Automated testing of CLI apps : A simple way to semi-automate testing of a CLI (Command Line Interface) app is by using input/output re-direction. Test automation using test drivers : JUnit is a tool for automated testing of Java programs. Automated testing of GUIs : testing tools like TestFX, Visual Studio, Selenium Test coverage : Test coverage is a metric used to measure the extent to which testing exercises the code. Function/ method coverage: based on functions executed e.g., testing executed 90 out of 100 functions. Statement coverage: based on the number of lines of code executed e.g., testing executed 23k out of 25k LOC. Decision/branch coverage: based on the decision points exercised e.g., an if statement evaluated to both true and false with separate test cases during testing is considered 'covered'. Condition coverage: based on the boolean sub-expressions, each evaluated to both true and false with different test cases. Condition coverage is not the same as the decision coverage. Path coverage: measures coverage in terms of possible paths through a given part of the code executed. 100% path coverage means all possible paths have been executed. A commonly used notation for path analysis is called the Control Flow Graph (CFG). Entry/exit coverage: measures coverage in terms of possible calls to and exits from the operations in the SUT. Entry points refer to all places from which the method is called from the rest of the code i.e., all places where the control is handed over to the method in concern. Exit points refer to points at which the control is returned to the caller e.g., return statements, throwing of exceptions. Dependency injection : Dependency injection is the process of 'injecting' objects to replace current dependencies with a different object. Often used to inject stubs to isolate the SUT from its dependencies so that it can be tested in isolation. Polymorphism can be used to implement dependency injection. Test-driven development (TDD) : Advocates writing the tests before writing the SUT, while evolving functionality and tests in small increments.","title":"Test Automation Testing"},{"location":"cs2106/cs2106-notes/","text":"CS2106 Notes AY23/24 Sem2 CS2106 Notes AY23/24 Sem2 Operating Systems Operating System Structure Running OSes Process Management Process Abstraction Component Description Basic Instruction Execution Memory Context Function Call Dynamically Allocated Memory OS Context Processes Process Scheduling Concurrent Execution Process Scheduling Algorithms First-Come First-Serve: FCFS Shortest Job First: SJF Shortest Remaining Time: SRT Round Robin: RR Priority Scheduling Multi-level Feedback Queue (MLFQ) Lottery Scheduling Scheduling for Interactive Systems Process Alternative - Threads Motivation for Thread Process and Thread Context Switch Operating Systems Operating system: A program that acts as an intermediary between a computer user and the computer hardware. Motivation for OS Abstraction: Hide the different low level details Present the common high level functionality to user Resource Allocator: Manages all resources: CPU,Memory,Input/Outputdevices Arbitrate potentially conflicting requests: for efficient and fair resource use Control Program: Controls execution of programs: prevent errors and improper use of the computer and provides security and protection Operating System Structure A monolithic kernel is an operating system architecture where the entire operating system is working in kernel space A microkernel architecture is an operating system pattern where only basic functionality is provided in the core of the software system Inter-Process Communication (IPC) Address space management Thread management Layered systems Generalization of monolithic system Organize the components into hierarchy of layers Upper layers make use of the lower layers Lowest layer is the hardware Highest layer is the user interface Client-Server Model Variation of microkernel Two classes of processes: Client process request service from server process Server Process built on top of the microkernel Client and Server process can be on separate machine! Running OSes Motivation Operating system assumes total control of the hardware Operating system is hard to debug/ monitor Definition Virtual machine : a software emulation of hardware, also known as hypervisor Process Management Process Abstraction Information describing an executing program Process/ Task/ Job is a dynamic abstracton for execution program Process Scheduling Deciding which process get to execute Inter-Process Communication & Synchronization Passing information between processes Alternative to Process Light-weight process aka Thread Process Abstraction Component Description Memory Storage for instruction and data Cache Duplicate part of the memory for faster access Usually split into instruction cache and data cache Fetch unit Loads instruction from memory Location indicated by a special register: Program Counter (PC) Functional units Carry out the instruction execution Dedicated to different instruction type Registers Internal storage for the fastest access speed General purpose registers: accessible by user program Special register: program counter Basic Instruction Execution Instruction X is fetched Memory location indicated by Program Counter Instruction X dispatched to the corresponding Functional Unit Read operands if applicable, usually from memory or GPR Result computed Write value if applicable n Usually to memory or GPR Instruction X is completed PC updated for the next instruction Memory Context Function Call Stack memory The new memory region to store information during function invocation Information of function invocation is described by a stack frame Stack frame contains: Return address of the caller Arguments for the function Storage for local variables Top of stack region (first unused location) is indicated by a stack pointer Stack frame is added on top when a function is invoked Stack frame is removed from top when a function call ends Function call convention (example scheme) Frame pointer To facilitate the access of various stack frame items Points to a fixed location in a stack frame Saved register Number of general purpose registers on most processors are limited When GPRs are exhausted, use memory to hold the GPR value, then reuse GPR, value held can be restored afterwards (known as register spilling) Dynamically Allocated Memory Acquire new memory space during execution time - malloc() Observations Memory is allocated only at runtime (size is not known during compilation) -> cannot place in data region No definite deallocation timing (can be explicitly freed by programmer) -> cannot place in stack region Solution: set up a separate heap memory region Memory context: text, data, stack and heap Hardware context: general purpose register, program counter, stack pointer, stack frame pointer OS Context Processes Process Identification & Process States New New process created May still be under initialisation Ready Process is waiting to run Running Process being executed on CPU Blocked Process waiting for event Cannot execute until event is available Terminated Process has finished execution, may require OS cleanup Process Table & Process Control Block: Entire execution context for a process Kernel maintains PCB for all processes System calls Application program interface (API) to OS Provides way of calling facilities/ services in kernel Not the same as normal function call (have to change from user mode to kernel mode) User program invokes the library call (normal function call) Library call (usually in assembly code) places the system call number in a designated location E.g. Register Library call executes a special instruction to switch from user mode to kernel mode (commonly known as TRAP) Now in kernel mode, the appropriate system call handler is determined: Using the system call number as index This step is usually handled by a dispatcher System call handler is executed: Carry out the actual request System call handler ended: Control return to the library call Switch from kernel mode to user mode Library call return to the user program: via normal function return mechanism Exception and Interrupt Exception is synchronous : occur due to program execution Have to execute an exception handler Similar to a forced function call Interrupt is asynchronous : events that occur independent of program execution Program execution is suspended Have to execute an interrupt handler Process Scheduling Concurrent Execution Concurrent processes Logical concept to cover multitasked processes Terminology Scheduler: Part of the OS that makes scheduling decision Scheduling algorithm: The algorithm used by scheduler Processing environment Batch processing No user: no interaction required, no need to be responsive Interactive With active user interacting with system Should be responsive, consistent in response time Real time processing Have deadline to meet Usually periodic process Criteria for all processing environments Fairness Should get a fair share of CPU time No starvation Balance All parts of computing system should be utilised Types of scheduling policies Non-preemptive (cooperative) A process stayed scheduled in running state until it blocks or gives up the CPU voluntarily Preemptive A process is given a fixed time quota to run (possible to block or give up early) Process Scheduling Algorithms Criteria for batch processing Turnaround time : Total time taken, i.e. finish-arrival time Waiting time : Time spent waiting for CPU Throughput : Number of tasks finished per unit time i.e. Rate of task completion CPU utilization : Percentage of time when CPU is working on a task First-Come First-Serve: FCFS Tasks are stored on a First-In-First-Out (FIFO) queue based on arrival time Pick the first task in queue to run until the task is done OR the task is blocked Blocked task is removed from the FIFO queue When it is ready again, it is placed at the back of queue i.e. just like a newly arrive task Guaranteed to have no starvation: The number of tasks in front of task X in FIFO is always decreasing -> task X will get its chance eventually Shortcomings Convoy effect : FCFS algorithm is non-preemptive in nature, that is, once CPU time has been allocated to a process, other processes can get CPU time only after the current process has finished Shortest Job First: SJF Select task with the smallest total CPU time Need to know total CPU time for a task in advance Given a fixed set of tasks, average waiting time is minimised Starvation is possible: biased towards short jobs, such that long job may never get a chance Shortest Remaining Time: SRT Select job with shortest remaining (or expected) time New job with shorter remaining time can preempt currently running job Provide good service for short job even when it arrives late Round Robin: RR Tasks are stored in a FIFO queue Pick the first task from queue front to run until: A fixed time slice (quantum) elapsed The task gives up the CPU voluntarily The task is then placed at the end of queue to wait for another turn Blocked task will be moved to other queue to wait for its request Basically a preemptive version of FCFS Response time guarantee: Given n tasks and quantum q Time before a task get CPU is bounded by (n-1)q Timer interrupt needed: For scheduler to check on quantum expiry The choice of time quantum duration is important: Big quantum: Better CPU utilization but longer waiting time Small quantum: Bigger overhead (worse CPU utilization) but shorter waiting time Priority Scheduling Assign a priority value to all tasks, select task with highest priority value Variants Preemptive version: higher priority process can preempt running process with lower priority Non-preemptive version: late coming high priority process has to wait for next round of scheduling Shortcomings Low priority process can starve (worse in preemptive variant) Possible solutions Decrease the priority of currently running process after every time quantum Give the current running process a time quantum Priority Inversion : Priority inversion is a situation that can occur when a low-priority task is holding a resource such as a semaphore for which a higher-priority task is waiting Multi-level Feedback Queue (MLFQ) If Priority(A) > Priority(B) -> A runs If Priority(A) == Priority(B) -> A and B runs in RR Priority Setting/Changing rules: New job -> Highest priority If a job fully utilized its time slice -> priority reduced If a job give up / blocks before it finishes the time slice -> priority retained Lottery Scheduling Give out \u201clottery tickets\u201d to processes for various system resources When a scheduling decision is needed, a lottery ticket is chosen randomly among eligible tickets Responsive: a newly created process can participate in the next lottery A process can be given Y lottery tickets to distribute to its child process An important process can be given more lottery tickets Each resource can have its own set of tickets Different proportion of usage per resource per task Scheduling for Interactive Systems Criteria for Interactive Environment Response time : Time between request and response by system Predictability : Variation in response time, lesser variation -> more predictable Preemptive scheduling algorithms are used to ensure good response time Scheduler needs to run periodically Interval of timer interrupt (ITI) OS scheduler is triggered every timer interrupt Time Quantum Execution duration given to a process Could be constant or variable among the processes Must be multiples of interval of timer interrupt Large range of values Process Alternative - Threads Motivation for Thread Process is expensive: Process creation under the fork() model: duplicate memory space, duplicate most of the process context etc Context switch: Requires saving/restoration of process information It is hard for independent processes to communicate with each other: Independent memory space -> no easy way to pass information Requires Inter-Process Communication (IPC) Thread is invented to overcome the problems with process model Started out as a \"quick hack\" and eventually matured to be very popular mechanism Basic Idea: A traditional process has a single thread of control: only one instruction of the whole program is executing at any time Add more threads of control to the same process: multiple parts of the programs is executing at the same time conceptually Process and Thread A single proces can have multiple threads: multithreaded process Threads in the same process shares Memory context: text, data, heap OS context: process id, files Unique information needed for each thread Identification (usually thread id) Registers (general purpose and special) Stack Context Switch Process context switch involves: OS Context Hardware Context Memory Context Thread switch within the same process involves: Hardware context: Registers, \"Stack\" (actually just changing FP and SP registers)","title":"CS2106 Notes AY23/24 Sem2"},{"location":"cs2106/cs2106-notes/#cs2106-notes-ay2324-sem2","text":"CS2106 Notes AY23/24 Sem2 Operating Systems Operating System Structure Running OSes Process Management Process Abstraction Component Description Basic Instruction Execution Memory Context Function Call Dynamically Allocated Memory OS Context Processes Process Scheduling Concurrent Execution Process Scheduling Algorithms First-Come First-Serve: FCFS Shortest Job First: SJF Shortest Remaining Time: SRT Round Robin: RR Priority Scheduling Multi-level Feedback Queue (MLFQ) Lottery Scheduling Scheduling for Interactive Systems Process Alternative - Threads Motivation for Thread Process and Thread Context Switch","title":"CS2106 Notes AY23/24 Sem2"},{"location":"cs2106/cs2106-notes/#operating-systems","text":"Operating system: A program that acts as an intermediary between a computer user and the computer hardware. Motivation for OS Abstraction: Hide the different low level details Present the common high level functionality to user Resource Allocator: Manages all resources: CPU,Memory,Input/Outputdevices Arbitrate potentially conflicting requests: for efficient and fair resource use Control Program: Controls execution of programs: prevent errors and improper use of the computer and provides security and protection","title":"Operating Systems"},{"location":"cs2106/cs2106-notes/#operating-system-structure","text":"A monolithic kernel is an operating system architecture where the entire operating system is working in kernel space A microkernel architecture is an operating system pattern where only basic functionality is provided in the core of the software system Inter-Process Communication (IPC) Address space management Thread management Layered systems Generalization of monolithic system Organize the components into hierarchy of layers Upper layers make use of the lower layers Lowest layer is the hardware Highest layer is the user interface Client-Server Model Variation of microkernel Two classes of processes: Client process request service from server process Server Process built on top of the microkernel Client and Server process can be on separate machine!","title":"Operating System Structure"},{"location":"cs2106/cs2106-notes/#running-oses","text":"Motivation Operating system assumes total control of the hardware Operating system is hard to debug/ monitor Definition Virtual machine : a software emulation of hardware, also known as hypervisor","title":"Running OSes"},{"location":"cs2106/cs2106-notes/#process-management","text":"Process Abstraction Information describing an executing program Process/ Task/ Job is a dynamic abstracton for execution program Process Scheduling Deciding which process get to execute Inter-Process Communication & Synchronization Passing information between processes Alternative to Process Light-weight process aka Thread","title":"Process Management"},{"location":"cs2106/cs2106-notes/#process-abstraction","text":"","title":"Process Abstraction"},{"location":"cs2106/cs2106-notes/#component-description","text":"Memory Storage for instruction and data Cache Duplicate part of the memory for faster access Usually split into instruction cache and data cache Fetch unit Loads instruction from memory Location indicated by a special register: Program Counter (PC) Functional units Carry out the instruction execution Dedicated to different instruction type Registers Internal storage for the fastest access speed General purpose registers: accessible by user program Special register: program counter","title":"Component Description"},{"location":"cs2106/cs2106-notes/#basic-instruction-execution","text":"Instruction X is fetched Memory location indicated by Program Counter Instruction X dispatched to the corresponding Functional Unit Read operands if applicable, usually from memory or GPR Result computed Write value if applicable n Usually to memory or GPR Instruction X is completed PC updated for the next instruction","title":"Basic Instruction Execution"},{"location":"cs2106/cs2106-notes/#memory-context","text":"","title":"Memory Context"},{"location":"cs2106/cs2106-notes/#function-call","text":"Stack memory The new memory region to store information during function invocation Information of function invocation is described by a stack frame Stack frame contains: Return address of the caller Arguments for the function Storage for local variables Top of stack region (first unused location) is indicated by a stack pointer Stack frame is added on top when a function is invoked Stack frame is removed from top when a function call ends Function call convention (example scheme) Frame pointer To facilitate the access of various stack frame items Points to a fixed location in a stack frame Saved register Number of general purpose registers on most processors are limited When GPRs are exhausted, use memory to hold the GPR value, then reuse GPR, value held can be restored afterwards (known as register spilling)","title":"Function Call"},{"location":"cs2106/cs2106-notes/#dynamically-allocated-memory","text":"Acquire new memory space during execution time - malloc() Observations Memory is allocated only at runtime (size is not known during compilation) -> cannot place in data region No definite deallocation timing (can be explicitly freed by programmer) -> cannot place in stack region Solution: set up a separate heap memory region Memory context: text, data, stack and heap Hardware context: general purpose register, program counter, stack pointer, stack frame pointer","title":"Dynamically Allocated Memory"},{"location":"cs2106/cs2106-notes/#os-context","text":"","title":"OS Context"},{"location":"cs2106/cs2106-notes/#processes","text":"Process Identification & Process States New New process created May still be under initialisation Ready Process is waiting to run Running Process being executed on CPU Blocked Process waiting for event Cannot execute until event is available Terminated Process has finished execution, may require OS cleanup Process Table & Process Control Block: Entire execution context for a process Kernel maintains PCB for all processes System calls Application program interface (API) to OS Provides way of calling facilities/ services in kernel Not the same as normal function call (have to change from user mode to kernel mode) User program invokes the library call (normal function call) Library call (usually in assembly code) places the system call number in a designated location E.g. Register Library call executes a special instruction to switch from user mode to kernel mode (commonly known as TRAP) Now in kernel mode, the appropriate system call handler is determined: Using the system call number as index This step is usually handled by a dispatcher System call handler is executed: Carry out the actual request System call handler ended: Control return to the library call Switch from kernel mode to user mode Library call return to the user program: via normal function return mechanism Exception and Interrupt Exception is synchronous : occur due to program execution Have to execute an exception handler Similar to a forced function call Interrupt is asynchronous : events that occur independent of program execution Program execution is suspended Have to execute an interrupt handler","title":"Processes"},{"location":"cs2106/cs2106-notes/#process-scheduling","text":"","title":"Process Scheduling"},{"location":"cs2106/cs2106-notes/#concurrent-execution","text":"Concurrent processes Logical concept to cover multitasked processes Terminology Scheduler: Part of the OS that makes scheduling decision Scheduling algorithm: The algorithm used by scheduler Processing environment Batch processing No user: no interaction required, no need to be responsive Interactive With active user interacting with system Should be responsive, consistent in response time Real time processing Have deadline to meet Usually periodic process Criteria for all processing environments Fairness Should get a fair share of CPU time No starvation Balance All parts of computing system should be utilised Types of scheduling policies Non-preemptive (cooperative) A process stayed scheduled in running state until it blocks or gives up the CPU voluntarily Preemptive A process is given a fixed time quota to run (possible to block or give up early)","title":"Concurrent Execution"},{"location":"cs2106/cs2106-notes/#process-scheduling-algorithms","text":"Criteria for batch processing Turnaround time : Total time taken, i.e. finish-arrival time Waiting time : Time spent waiting for CPU Throughput : Number of tasks finished per unit time i.e. Rate of task completion CPU utilization : Percentage of time when CPU is working on a task","title":"Process Scheduling Algorithms"},{"location":"cs2106/cs2106-notes/#first-come-first-serve-fcfs","text":"Tasks are stored on a First-In-First-Out (FIFO) queue based on arrival time Pick the first task in queue to run until the task is done OR the task is blocked Blocked task is removed from the FIFO queue When it is ready again, it is placed at the back of queue i.e. just like a newly arrive task Guaranteed to have no starvation: The number of tasks in front of task X in FIFO is always decreasing -> task X will get its chance eventually Shortcomings Convoy effect : FCFS algorithm is non-preemptive in nature, that is, once CPU time has been allocated to a process, other processes can get CPU time only after the current process has finished","title":"First-Come First-Serve: FCFS"},{"location":"cs2106/cs2106-notes/#shortest-job-first-sjf","text":"Select task with the smallest total CPU time Need to know total CPU time for a task in advance Given a fixed set of tasks, average waiting time is minimised Starvation is possible: biased towards short jobs, such that long job may never get a chance","title":"Shortest Job First: SJF"},{"location":"cs2106/cs2106-notes/#shortest-remaining-time-srt","text":"Select job with shortest remaining (or expected) time New job with shorter remaining time can preempt currently running job Provide good service for short job even when it arrives late","title":"Shortest Remaining Time: SRT"},{"location":"cs2106/cs2106-notes/#round-robin-rr","text":"Tasks are stored in a FIFO queue Pick the first task from queue front to run until: A fixed time slice (quantum) elapsed The task gives up the CPU voluntarily The task is then placed at the end of queue to wait for another turn Blocked task will be moved to other queue to wait for its request Basically a preemptive version of FCFS Response time guarantee: Given n tasks and quantum q Time before a task get CPU is bounded by (n-1)q Timer interrupt needed: For scheduler to check on quantum expiry The choice of time quantum duration is important: Big quantum: Better CPU utilization but longer waiting time Small quantum: Bigger overhead (worse CPU utilization) but shorter waiting time","title":"Round Robin: RR"},{"location":"cs2106/cs2106-notes/#priority-scheduling","text":"Assign a priority value to all tasks, select task with highest priority value Variants Preemptive version: higher priority process can preempt running process with lower priority Non-preemptive version: late coming high priority process has to wait for next round of scheduling Shortcomings Low priority process can starve (worse in preemptive variant) Possible solutions Decrease the priority of currently running process after every time quantum Give the current running process a time quantum Priority Inversion : Priority inversion is a situation that can occur when a low-priority task is holding a resource such as a semaphore for which a higher-priority task is waiting","title":"Priority Scheduling"},{"location":"cs2106/cs2106-notes/#multi-level-feedback-queue-mlfq","text":"If Priority(A) > Priority(B) -> A runs If Priority(A) == Priority(B) -> A and B runs in RR Priority Setting/Changing rules: New job -> Highest priority If a job fully utilized its time slice -> priority reduced If a job give up / blocks before it finishes the time slice -> priority retained","title":"Multi-level Feedback Queue (MLFQ)"},{"location":"cs2106/cs2106-notes/#lottery-scheduling","text":"Give out \u201clottery tickets\u201d to processes for various system resources When a scheduling decision is needed, a lottery ticket is chosen randomly among eligible tickets Responsive: a newly created process can participate in the next lottery A process can be given Y lottery tickets to distribute to its child process An important process can be given more lottery tickets Each resource can have its own set of tickets Different proportion of usage per resource per task","title":"Lottery Scheduling"},{"location":"cs2106/cs2106-notes/#scheduling-for-interactive-systems","text":"Criteria for Interactive Environment Response time : Time between request and response by system Predictability : Variation in response time, lesser variation -> more predictable Preemptive scheduling algorithms are used to ensure good response time Scheduler needs to run periodically Interval of timer interrupt (ITI) OS scheduler is triggered every timer interrupt Time Quantum Execution duration given to a process Could be constant or variable among the processes Must be multiples of interval of timer interrupt Large range of values","title":"Scheduling for Interactive Systems"},{"location":"cs2106/cs2106-notes/#process-alternative-threads","text":"","title":"Process Alternative - Threads"},{"location":"cs2106/cs2106-notes/#motivation-for-thread","text":"Process is expensive: Process creation under the fork() model: duplicate memory space, duplicate most of the process context etc Context switch: Requires saving/restoration of process information It is hard for independent processes to communicate with each other: Independent memory space -> no easy way to pass information Requires Inter-Process Communication (IPC) Thread is invented to overcome the problems with process model Started out as a \"quick hack\" and eventually matured to be very popular mechanism Basic Idea: A traditional process has a single thread of control: only one instruction of the whole program is executing at any time Add more threads of control to the same process: multiple parts of the programs is executing at the same time conceptually","title":"Motivation for Thread"},{"location":"cs2106/cs2106-notes/#process-and-thread","text":"A single proces can have multiple threads: multithreaded process Threads in the same process shares Memory context: text, data, heap OS context: process id, files Unique information needed for each thread Identification (usually thread id) Registers (general purpose and special) Stack","title":"Process and Thread"},{"location":"cs2106/cs2106-notes/#context-switch","text":"Process context switch involves: OS Context Hardware Context Memory Context Thread switch within the same process involves: Hardware context: Registers, \"Stack\" (actually just changing FP and SP registers)","title":"Context Switch"},{"location":"dsa-notes/dsa-notes/","text":"Data Structures and Algorithm Data Structures and Algorithm Recurrence Relations Binary Search Peak Finding Sorting BubbleSort SelectionSort InsertionSort MergeSort QuickSort Partition QuickSelect Trees Binary Search Trees Height Search Insert Traversals Inorder Traversal Preorder Traversal Postorder Traversal Delete Balanced Trees AVL Insert Delete Tries Dynamic Order Statistics Interval Trees Insert Interval Search 1D Range Trees Query 2D Range Trees Priority Queue Binary (Max) Heaps Insert DecreaseKey Delete Heap vs AVL Tree HeapSort Disjoint Set Quick Find: using an int[] componentId Quick Union: using an int[] parent Weighted Union Weighted Union with Path Compression Hashing Direct Access Table Chaining Open Addressing Resizing Table Graph Breadth-First Search Depth-First Search Shortest Path Bellman-Ford Dijkstra's Algorithm Minimum Spanning Trees Prim's Algorithm Kruskal's Algorithm Dynamic Programming Topological Sort Recurrence Relations T(n) = T(n-1) + O(1) = O(n) T(n) = T(n/2) + O(1) = O(logn) T(n) = T(n-1) + O(n) = O(n^2) T(n) = T(n-1) + O(nk) = O(n^(k+1)) T(n) = 2T(n/2) + O(n) = O(nlogn) T(n) = T(n/2) + O(n) = O(n) T(n) = 2T(n/2) + O(1) = O(n) T(n) = 2T(n-1) + O(1) = O(2^n) Binary Search Time complexity: O(logn) Preconditions: Array is of size n Array is sorted Postconditions: If element is in array: A[left] = key Loop invariant: A[left] <= key <= A[right] (right - left) <= n/2^k in iteration k public int search(int A[], int key, int n) { int left = 0; int right = n - 1; while (left < right) { // int mid = (left + right) / 2 can lead to integer overflow int mid = left + (right - left) / 2; if (key <= A[mid]) { right = mid; } else { left = mid + 1; } } return (A[left] == key ? left : -1); } Peak Finding Output a local maximum in A, where A[i - 1] <= A[i] and A[i + 1] <= A[i] Time complexity: O(logn) Invariant: If we recuse in the right half, then there exists a peak in the right half There exists a peak in the range [begin, end] Every peak in [begin, end] is a peak in [1, n] T(n) = T(n/2) + \u03b8(1) = O(logn) public int findPeak(int A[], int n) { // if right of mid is larger, recurse on right if (A[n / 2 + 1] > A[n / 2]) { return findPeak(Arrays.copyOfRange(A, n / 2 + 1, n + 1), n / 2) // if left of mid is larger, recurse on left } else if (A[n / 2 - 1] > A[n / 2]) { return findPeak(Arrays.copyOfRange(A, 0, n / 2), n / 2) } else { return n / 2; } } Sorting BubbleSort Invariant: At the end of iteration i, the biggest j items are correctly sorted in the final j positions of the array. Best: O(n), when array is already sorted Worst: O(n^2) , when array is reverse sorted Stable Description: For n loops, if A[j] > A[j + 1], swap(A[j], A[j + 1]) void bubbleSort(int arr[], int n) { int i, j, temp; boolean swapped; for (i = 0; i < n - 1; i++) { swapped = false; for (j = 0; j < n - i - 1; j++) { if (arr[j] > arr[j + 1]) { // Swap arr[j] and arr[j+1] temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; swapped = true; } } // If no two elements were // swapped by inner loop, then break if (swapped == false) break; } } SelectionSort Invariant: At the end of iteration j: the smallest j items are correctly sorted in the first j positions of the array. Best: O(n^2) Worst: O(n^2) Not stable Description: For n loops, find minimum element A[j] in A[j..n], swap(A[j], A[k]) void selectionSort(int arr[], int n) { int min_idx = 0; // One by one move boundary of unsorted subarray for (int i = 0; i < n - 1; i++) { // Find the minimum element in unsorted array min_idx = i; for (int j = i + 1; j < n; j++) { if (arr[j] < arr[min_idx]) min_idx = j; } // Swap the found minimum element with the first element if (min_idx != i) swap(arr[min_idx], arr[i]); } } InsertionSort Invariant: At the end of iteration j: the first j items in the array are in sorted order. Best: O(n), when array is already sorted Worst: O(n^2) , when array is reverse sorted Stable Description: For n loops, insert key into the sorted array A[1 .. j - 1] void insertionSort(int arr[]) { int n = arr.length; for (int i = 1; i < n; ++i) { int key = arr[i]; int j = i - 1; /* Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position */ while (j >= 0 && arr[j] > key) { arr[j + 1] = arr[j]; j = j - 1; } arr[j + 1] = key; } } MergeSort Best: O(n logn) Worst: O(n logn) Stable Memory: O(n logn) Description: Divide: split array into two halves Recurse: sort the two halves Combine: merge the two sorted halves Use InsertionSort instead for n < 1024 void merge(int arr[], int l, int m, int r) { // Find sizes of two subarrays to be merged int n1 = m - l + 1; int n2 = r - m; // Create temp arrays int L[] = new int[n1]; int R[] = new int[n2]; // Copy data to temp arrays for (int i = 0; i < n1; ++i) L[i] = arr[l + i]; for (int j = 0; j < n2; ++j) R[j] = arr[m + 1 + j]; // Merge the temp arrays // Initial indices of first and second subarrays int i = 0, j = 0; // Initial index of merged subarray array int k = l; while (i < n1 && j < n2) { if (L[i] <= R[j]) { arr[k] = L[i]; i++; } else { arr[k] = R[j]; j++; } k++; } // Copy remaining elements of L[] if any while (i < n1) { arr[k] = L[i]; i++; k++; } // Copy remaining elements of R[] if any while (j < n2) { arr[k] = R[j]; j++; k++; } } void mergeSort(int arr[], int l, int r) { if (l < r) { // Find the middle point int m = l + (r - l) / 2; // Sort first and second halves mergeSort(arr, l, m); mergeSort(arr, m + 1, r); // Merge the sorted halves merge(arr, l, m, r); } } QuickSort Invariant: At the end of every loop iteration, For every i < low: B[i] < pivot For every j > high: B[j] > pivot Best: O(n logn) , when median element is chosen as pivot Worst: O(n^2) , when first element is chosen as pivot/ all elements are the same Not stable Description: Divide: Partition the array into two sub-arrays around a pivot x such that elements in lower subarray \u2264 x \u2264 elements in upper sub-array. Conquer: Recursively sort the two sub-arrays. Combine: Trivial, do nothing. void quickSort(int[] arr, int low, int high) { if (low < high) { // pi is partitioning index, arr[pi] // is now at right place int pi = partition(arr, low, high); // Separately sort elements before // partition and after partition quickSort(arr, low, pi - 1); quickSort(arr, pi + 1, high); } } Partition Invariant: A[high] > pivot at the end of each loop At the end of every loop iteration For all i >= high, A[i] > pivot For all 1 < j < low, A[j] < pivot Time complexity: O(n) int partition(int[] arr, int low, int high) { // Choosing the pivot int pivot = arr[high]; // Index of smaller element and indicates // the right position of pivot found so far int i = (low - 1); for (int j = low; j <= high - 1; j++) { // If current element is smaller than the pivot if (arr[j] < pivot) { // Increment index of smaller element i++; swap(arr, i, j); } } swap(arr, i + 1, high); return (i + 1); } QuickSelect Invariant: After partioning, arr[partition] is now at right place Time complexity: O(n) Description: Find the k-th smallest element in an unordered list partition the array if partition is at position k, the partition is the k-th smallest element else continue searching in the correct half // ASSUMPTION: all elements in arr[] are distinct int kthSmallest(int[] arr, int low, int high, int k) { // find the partition int partition = partition(arr, low, high); // if partition value is equal to the kth position, return value at k if (partition == k - 1) { return arr[partition]; } // if partition value is less than kth position, search right side of the array else if (partition < k - 1) { return kthSmallest(arr, partition + 1, high, k); } // if partition value is more than kth position, search left side of the array else { return kthSmallest(arr, low, partition - 1, k); } } Trees Binary Search Trees All in left sub-tree < key < all in right sub-tree Height Number of edges on longest path from root to leaf h(v) = 0 (if v is a leaf) h(v) = max(h(v.left), h(v.right)) + 1 Time complexity: O(logn) int height() { int leftHeight = -1; int rightHeight = -1; if (leftTree != null) { leftHeight = leftTree.height(); } if (rightTree != null) { rightHeight = rightTree.height(); } return max(leftHeight, rightHeight) + 1; } Search Worst case: O(n) , (when n = h) Time complexity: O(h) searchMax() TreeNode searchMax() { if (rightTree != null) { return rightTree.searchMax(); } else { return this; } } searchMin() TreeNode searchMin() { if (leftTree != null) { return leftTree.searchMin(); } else { return this; } } search(int queryKey) public TreeNode search(int queryKey){ if (queryKey < key) { if (leftTree != null) { return leftTree.search(key); } else { return null; } } else if (queryKey > key) { if (rightTree != null) { return rightTree.search(key); } else { return null; } } else { return this; // Key is here! } } Insert void insert(int insKey, int intValue) { if (insKey < key) { if (leftTree != null) { leftTree.insert(insKey); } else { leftTree = new TreeNode(insKey,insValue) } } else if (insKey > key) { if (rightTree != null) { rightTree.insert(insKey); } else { rightTree = new TreeNode(insKey, insValue); } } else { return; // Key is already in the tree! } } Traversals Inorder Traversal Left, self, right Running time: O(n) void inOrder(Node node) { if (node == null) return; // First recur on left child inOrder(node.left); // Then print the data of node System.out.print(node.key + \" \"); // Now recur on right child inOrder(node.right); } Preorder Traversal Self, left, right Running time: O(n) void preOrder(Node node) { if (node == null) return; // Print the data of node System.out.print(node.key + \" \"); // Then recur on left child preOrder(node.left); // Now recur on right child preOrder(node.right); } Postorder Traversal Left, right, self Running time: O(n) void postOrder(Node node) { if (node == null) return; // First recur on left child postOrder(node.left); // Then recur on right child postOrder(node.right); // Now print the data of node System.out.print(node.key + \" \"); } Delete Successor Running time: O(h) Idea: Search for key in the tree. If (result > key), then return result. If (result <= key), then search for successor of result. Case 1: node has a right child Case 2: node has no right child public TreeNode successor() { if (rightTree != null) { return rightTree.searchMin(); } TreeNode parent = parentTree; TreeNode child = this; while ((parent != null) && (child == parent.rightTree)) { child = parent; parent = child.parentTree; } return parent; } Delete Running time: O(h) Case 1: no children Remove v Case 2: 1 child Remove v Connect child(v) to parent(v) Case 3: 2 children x = successor(v) Delete(x) Remove v Connect x to left(v), right(v), parent(v) Balanced Trees BST is balanced if h = O(logn) All operations run in O(logn) time Maxmimum height: h < 2logn Mininimum nodes: n > 2^(h/2) In every node v, store height (augment) On insert and delete, update height: height = max(left.height, right.height) + 1 Define Invariant A node v is height-balanced if |v.left.height - v.right.height| <= 1 A BST is height-balanced if every node is height-balanced Maintain balance // assume v has left != null void rightRotate(TreeNode v) { TreeNode w = v.left; w.parent = v.parent; v.parent = w; v.left = w.right; w.right = v; } // assume v has right != null void leftRotate(TreeNode v) { TreeNode w = v.right; w.parent = v.parent; v.parent = w; v.right = w.left; w.left = v; } If v is out of balanced and left-heavy: Case 1: v.left is balanced -> rightRotate(v) Case 2: v.left is left-heavy -> rightRotate(v) Case 3: v.left is right-heavy -> leftRotate(v.left), rightRotate(v) If v is out of balanced and right-heavy: Case 1: v.right is balanced -> leftRotate(v) Case 2: v.right is left-heavy -> leftRotate(v) Case 3: v.right is right-heavy -> rightRotate(v.right), leftRotate(v) import java.util.TreeSet; TreeSet<IntegerNode> leftHalf; TreeSet<IntegerNode> rightHalf; void rebalance() { int leftSize = this.leftHalf.size(); int rightSize = this.rightHalf.size(); int diff = Math.abs(leftSize - rightSize); if (diff > 1) { if (leftSize > rightSize) { // Left is bigger, move the biggest item to right this.rightHalf.add(this.leftHalf.pollLast()); } else { // Right is bigger, move the smallest item to left this.leftHalf.add(this.rightHalf.pollFirst()); } } } AVL Insert Summary: Insert key in BST Walk up tree: At every step, check for balance If out-of-balance, use rotations to rebalance and return Key observation: Only need to fix lowest out-of-balance node Only need at most two rotations to fix Delete If v has two children, swap it with its successor Delete node v from binary tree (and reconnect children) For every ancestor of the deleted node: Check if it is height-balanced If not, perform a rotation Continue to the root Summary: Delete key from BST Walk up tree: At every step, check for balance If out-of-balance, use rotations to rebalance continue to root Key observation: Needs at most O(logn) rotations import java.util.*; import java.io.*; class Node { int key, height; Node left, right; Node (int d) { key = d; height = 1; } } class AVLTree { Node root; int height (Node N) { if (N == null) return 0; return N.height; } int max (int a, int b) { return (a > b) ? a : b; } Node rightRotate (Node y) { Node x = y.left; Node T2 = x.right; x.right = y; y.left = T2; y.height = max (height (y.left), height (y.right)) + 1; x.height = max (height (x.left), height (x.right)) + 1; return x; } Node leftRotate (Node x) { Node y = x.right; Node T2 = y.left; y.left = x; x.right = T2; x.height = max (height (x.left), height (x.right)) + 1; y.height = max (height (y.left), height (y.right)) + 1; return y; } int getBalance (Node N) { if (N == null) return 0; return height (N.left) - height (N.right); } Node insert (Node node, int key) { if (node == null) return (new Node (key)); if (key < node.key) node.left = insert (node.left, key); else if (key > node.key) node.right = insert (node.right, key); else return node; node.height = 1 + max (height (node.left), height (node.right)); int balance = getBalance (node); if (balance > 1 && key < node.left.key) return rightRotate (node); if (balance < -1 && key > node.right.key) return leftRotate (node); if (balance > 1 && key > node.left.key) { node.left = leftRotate (node.left); return rightRotate (node); } if (balance < -1 && key < node.right.key) { node.right = rightRotate (node.right); return leftRotate (node); } return node; } } Tries Cost of comparing two strings in a tree: O(hL) Cost in trie: O(L) Space for storing a try: O(size of text * overhead) Dynamic Order Statistics Select(k) : finds the node with rank k // augmented tree with weight // O(logn) Node select(k) { rank = m_left.weight + 1; if (k == rank) { return v; } else if (k < rank) { return m_left.select(k); } else if (k > rank) { return m_right.select(k\u2013rank); } } // in-order traversal method // O(n) Node kthSmallest(int k) { Result result = new Result(0, null); inOrderTraversal(root, k, result); return result.result; } void inOrderTraversal(Node node, int k, Result result) { if (node == null || result.count >= k) { return; } inOrderTraversal(node.left, k, result); result.count++; if (result.count == k) { result.result = node; return; } inOrderTraversal(node.right, k, result); } class Result { int count; Node result; Result(int count, Node result) { this.count = count; this.result = result; } } Rank(v) : computes the rank of a node v // augmented tree with weight // O(logn) int rank(TreeNode node) { rank = node.left.weight + 1; while (node != null) { if (node.parent.left == node) { continue; } else { rank += node.parent.left.weight + 1; } node = node.parent; } return rank; } // recursion method // worst case: O(n) int rank(TreeNode node, int x) { if (node == null) { return 0; } if (node.value <= x) { return 1 + rank(node.left, x) + rank(node.right,x); } else { return rank(node.left, x) } } Interval Trees Augment tree with maximum endpoint in subtree class Node { int[] interval; int maxEnd; Node left, right; int height; Node(int[] interval) { this.interval = interval; this.maxEnd = interval[1]; this.left = this.right = null; this.height = 1; } } Insert class IntervalTree { private int height(Node node) { return (node == null) ? 0 : node.height; } private int maxEnd(Node node) { return (node == null) ? Integer.MIN_VALUE : node.maxEnd; } private int getBalance(Node node) { return (node == null) ? 0 : height(node.left) - height(node.right); } private Node insert(Node root, int[] interval) { if (root == null) { return new Node(interval); } if (interval[0] < root.interval[0]) { root.left = insert(root.left, interval); } else { root.right = insert(root.right, interval); } root.height = Math.max(height(root.left), height(root.right)) + 1; root.maxEnd = Math.max(root.interval[1], Math.max(maxEnd(root.left), maxEnd(root.right))); int balance = getBalance(root); // Left Heavy if (balance > 1) { if (interval[0] < root.left.interval[0]) { return rotateRight(root); } else { root.left = rotateLeft(root.left); return rotateRight(root); } } // Right Heavy if (balance < -1) { if (interval[0] > root.right.interval[0]) { return rotateLeft(root); } else { root.right = rotateRight(root.right); return rotateLeft(root); } } return root; } } Interval Search Find interval containing x Running time: O(logn) boolean isInInterval(Node c, int x) { return x >= c.interval[0] && x <= c.interval[1]; } int[] intervalSearch(int x) { Node c = root; while (c != null && !isInInterval(c, x)) { if (c.left == null) { c = c.right; } else if (x > c.left.maxEnd) { c = c.right; } else { c = c.left; } } return c.interval; } All-Overlaps: List all intervals that overlap with point Running time if there are k overlapping intervals: O(k logn) Repeat until no more intervals: Search for interval. Add to list. Delete interval. Repeat for all intervals on list: Add interval back to tree. 1D Range Trees Strategy: Use a binary search tree. Store all points in the leaves of the tree. (Internal nodes store only copies.) Each internal node v stores the MAX of any leaf in the left sub-tree. Query Invariant: The search interval for a left-traversal at node v includes the maximum item in the subtree rooted at v. Algorithm: Find split node, takes O(logn) Do left traversal Do right traversal Query time complexity: O(k + logn), where k is number of points found Preprocessing (buildtree) time complexity: O(n logn) Total space complexity: O(n) Node FindSplit(int low, int high) { Node v = root; done = false; while (!done) { if (high <= v.key) { v = v.left; } else if (low > v.key) { v = v.right; } else { done = true } } return v; } // LeftTraversal either: // 1. Output all right sub-tree and recurse left. // 2. Recurse right. void LeftTraversal(Node v, int low, int high) { boolean isInRange = low <= v.key; boolean isLeafNode = v.left == null && v.right == null; if (isLeafNode && isInRange) { System.out.println(v.key); } if (isInRange) { // if in range, take the all of right subtree's leafs AllLeafTraversal(v.right); LeftTraversal(v.left, low, high); } else { LeftTraversal(v.right, low, high); } } void RightTraversal(Node v, int low, int high) { boolean isInRange = v.key <= high; boolean isLeafNode = v.left == null && v.right == null; if (isLeafNode && isInRange) { System.out.println(v.key); } if (isInRange) { // if in range, take the all of left subtree's leafs AllLeafTraversal(v.left); RightTraversal(v.right, low, high); } else { RightTraversal(v.left, low, high); } } void AllLeafTraversal(Node v) { if (v == null) { return; } // only leaf nodes are printed if (v.left == null && v.right == null) { System.out.println(v.key); } AllLeafTraversal(v.left); AllLeafTraversal(v.right); } void Query(low, high) { Node v = FindSplit(low, high); LeftTraversal(v.left, low, high); RightTraversal(v.right, low, high); } 2D Range Trees Build an x-tree using only x-coordinates. For every node in the x-tree, build a y-tree out of nodes in subtree using only y-coordinates. Query time: O((logn)^2 + k) O(logn) to find split node O(logn) recursing steps O(logn) y-tree-searches of cost O(logn) O(k) enumerating output Space complexity: O(n logn) Each point appears in at most one y-tree per level There are O(log n) levels Query cost: O((logn)^d + k) buildTree cost: O(n (logn)^d-1) Space: O(n (logn)^d-1) Priority Queue Return Type Operation Description void insert(Key k, Priority p) insert k with priority p Data extractMin() remove key with min. priority void decreaseKey(Key k, Priority p) reduce the priority of key k to priority p boolean contains(Key k) whether queue contains key k boolean isEmpty() whether queue is empty Sorted array Insert: O(n) extractMax: O(1) Unsorted array insert: O(1) extractMax: O(n) AVL tree (indexed by priority) insert: O(logn) extractMax: O(logn) AVL tree and dictionary contains: O(1) decreaseKey: O(logn) Binary (Max) Heaps Heap ordering: priority[parent] >= priority[child] Complete binary tree Every level is full, except possibly the last All nodes are as far left as possible Height: O(logn) (maximum height is floor(logn)) Operations: O(logn) Implements a max priority queue Return Type Operation Description void insert(Key k, Priority p) insert k with priority p Data extractMax() remove key with max priority void increaseKey(Key k, Priority p) increase the priority of key k to priority p void decreaseKey(Key k, Priority p) reduce the priority of key k to priority p Data delete(Key k) delete k from heap left(x) = 2 * x + 1 right(x) = 2 * x + 2 parent(x) = floor((x - 1) / 2) Where x is the position of the node in the array Insert Add leaf of new node at leftmost position Bubble up (swap with parent) until condition priority[parent] >= priority[child] fulfilled bubbleUp(Node v) { while (v != null) { if (priority(v) > priority(parent(v))) { swap(v, parent(v)); } else { return; } v = parent(v); } } insert(Priority p, Key k) { Node v = tree.insert(p, k); bubbleUp(v); } DecreaseKey Update priority Bubble down (swap with child that has higher priority) bubbleDown(Node v) { while (!isLeaf(v)) { leftP = priority(left(v)); rightP = priority(right(v)); maxP = max(leftP, rightP, priority(v)); if (leftP == max) { swap(v, left(v)); v = left(v); } else if (rightP == max) { swap(v, right(v)); v = right(v); } else { return; } } } Delete Swap deleted node with last node (which is last element in array) Remove last node Bubble down swapped node ExtractMax: delete(root); Heap vs AVL Tree Same asymptotic cost for operations Faster real cost (no constant factors) Simpler: no rotations Slightly better concurrency HeapSort Running time: O(n logn) In-place Deterministic, and will always take O(n logn) Faster than MergeSort, a little slower than QuickSort Not stable Unsorted list --> heap (running time: O(n)), specifically 2 * O(n) Base case: each leaf is a heap Recursion: siblings + parent nodes = heap (bubbleDown) // int[] A = array of unsorted integers for (int i = n - 1; i >= 0; i--) { bubbleDown(i, A); // O(height), but more than n/2 of nodes are leaves with height = 0 } Heap --> sorted list () (running time: O(n logn)) Fill array from last position to first position, by recursively calling extractMax() //int[] A = array stored as a heap for (int i = n - 1; i >= 0; i--) { int value = extractMax(A); //O(logn) A[i] = value; } Disjoint Set Determine if objects are connected Quick Find: using an int[] componentId Store component identifier of each object Find: O(1) Finds whether p and q are connected boolean find(int p, int q) { return(componentId[p] == componentId[q]); } Union: O(n) Make p and q have the same componentId Traverse the component identifier array: if id = q's id, update to be p's id void union(int p, int q) { updateComponent = componentId[q]; for (int i=0; i<componentId.length; i++) { if (componentId[i] == updateComponent) { componentId[i] = componentId[p]; } } } Quick Union: using an int[] parent Two objects are connected if they are part of the same tree Find: O(n) Traverse up the tree from given node, to find parent If final parents are the same, they are connected boolean find(int p, int q) { while (parent[p] != p) { p = parent[p]; } while (parent[q] != q) { q = parent[q]; } return (p == q); } Union: O(n), height of tree can be n Traverse up the tree from given node, to find parent Set parent of p to be q void union(int p, int q) { while (parent[p] != p) { p = parent[p]; } while (parent[q] != q) { q = parent[q]; } parent[p] = q; } Weighted Union Choose the larger element to be the parent during union Maximum depth of tree: O(logn) Running time of find : O(logn) Running time of union : O(logn) union(int p, int q) { while (parent[p] !=p) { p = parent[p]; } while (parent[q] !=q) { q = parent[q]; } if (size[p] > size[q]) { parent[q] = p; // Link q to p size[p] = size[p] + size[q]; } else { parent[p] = q; // Link p to q size[q] = size[p] + size[q]; } } Weighted Union with Path Compression After finding root, set the parent of each traversed node to the root Tree height is compressed // Takes O(logn) time findRoot(int p) { root = p; while (parent[root] != root) { root = parent[root]; } while (parent[p] != p) { temp = parent[p]; parent[p] = root; p = temp; } return root; } union(int p, int q) { p = findRoot(p); q = findRoot(q); if (size[p] > size[q]) { parent[q] = p; // Link q to p size[p] = size[p] + size[q]; } else { parent[p] = q; // Link p to q size[q] = size[p] + size[q]; } } Starting from empty, any sequence of m union/find operations on n objects takes: O(n + m\u03b1(m, n))time. Path compression is helpful with more union/ find operations First operation will still take the same amount of time (+ path compression for future operations) \u03b1 = ackermann function (between O(1) and O(logn)) Running time of find : \u03b1(m, n) Running time of union : \u03b1(m, n) Hashing Implement symbol table with an AVL tree: C(insert) = O(logn); C(search) = O(logn) Direct Access Table Using a table, indexed by keys Insert: O(1), Search: O(1) Space: m buckets Hash function defined to derive key Impossible to choose a hash function with no collisions (pigeonhole principle) Chaining Insert a linked list in the table, indexed by keys Space: O(m + n); table size is m, linked list size is n Insert: O(1 + cost(h)) Worst case search: O(n + cost(h)) (when all keys hash to the same bucket, cost is n) With SUHA, E(search time) = 1 + n/m = O(1) Maximum chain length with SUHA = O(logn) = \u0398(logn / loglogn) Simple uniform hashing assumption (made of the hashing function) Every key is equally likely to map to every bucket Keys are mapped independently P(i'th key is put in bucket j) = 1/m Open Addressing All data directly stored in the table, with one item per slot On collision, probe a sequence of buckets until an empty one is found Delete Set bucket to DELETED , instead of leaving it empty So that search can find an element Properties of good hash function h(key, i) enumerates all possible buckets Simple Uniform Hashing Assumption Linear probing can lead to clusters: O(n) Assuming uniform hashing, E(cost of operations) = 1 / (1 - a) a = n / m Performance degrades badly as a -> 1 Double Hashing Using two hash functions, define a new hash function: h(k, i) = f(k) + i * g(k) mod m Resizing Table Cost of resize from m to m + 1 Cost of double size: O(n) (done when the table is full) Cost of inserting n items + resizing: O(n) Most insertions: O(1) Average cost: O(1) Half the table size when table is 3/4 empty Cost of squared table size: O(n^2) Cost of inserts: O(n) Deleting elements: O(1 + n/m) Graph Diameter: maximum distance between two notes, following the shortest path Special graphs Star: one central node, all edges connect centre to edges; diameter = 2 Clique: complete graph, degree = n - 1; diameter = 1 Line or path: degree = 2; diameter = n - 1 Cycle: degree = 2; diameter = n/2 or n/2 - 1 Bipartite graph: nodes divided into two sets with no edges between nodes in the same set; diameter = n - 1 Memory usage of graph G | | Adjacency List | Adjacency Matrix | | ------------ | -------------- | ---------------- | | Graph (V, E) | O(V + E) | O(V^2) | | Cycle | O(V) | O(V^2) | | Clique | O(V^2) | O(V^2) | Breadth-First Search BFS with adjacency list: O(V + E) // With an adjacency list void BFS(int s) { // Mark all the vertices as not visited boolean visited[] = new boolean[V]; // Create a queue for BFS LinkedList<Integer> queue = new LinkedList<Integer>(); // Mark the current node as visited and enqueue it visited[s] = true; queue.add(s); while (queue.size() != 0) { // Dequeue a vertex from queue and print it s = queue.poll(); System.out.print(s + \" \"); // Get all adjacent vertices of the dequeued // vertex s. // If an adjacent has not been visited, // then mark it visited and enqueue it Iterator<Integer> i = adj[s].listIterator(); while (i.hasNext()) { int n = i.next(); if (!visited[n]) { visited[n] = true; queue.add(n); } } } } BFS with adjacency matrix: O(V^2) // With an adjacency matrix void BFS(int start) { // A vertex is not visited more than once // Initializing the vector to false at the beginning boolean[] visited = new boolean[v]; Arrays.fill(visited, false); List<Integer> q = new ArrayList<>(); q.add(start); // Set source as visited visited[start] = true; int vis; while (!q.isEmpty()) { vis = q.get(0); // Print the current node System.out.print(vis + \" \"); q.remove(q.get(0)); // For every adjacent vertex to the current vertex for(int i = 0; i < v; i++) { if (adj[vis][i] == 1 && (!visited[i])) { // Push the adjacent node to the queue q.add(i); visited[i] = true; } } } } Depth-First Search DFS with adjacency list: O(V + E) // With an adjacency list void DFSUtil(int v, boolean visited[]) { // Mark the current node as visited and print it visited[v] = true; System.out.print(v + \" \"); // Recurse for all adjacent vertices Iterator<Integer> i = adj[v].listIterator(); while (i.hasNext()) { int n = i.next(); if (!visited[n]) DFSUtil(n, visited); } } void DFS(int v) { // Mark all the vertices as // not visited(set as // false by default in java) boolean visited[] = new boolean[V]; // Call the recursive helper // function to print DFS // traversal DFSUtil(v, visited); } DFS with adjacency matrix: O(V^2) // With an adjacency matrix static void dfs(int start, boolean[] visited) { // Print the current node System.out.print(start + \" \"); // Set current node as visited visited[start] = true; // For every node of the graph for (int i = 0; i < adj[start].length; i++) { // If some node is adjacent to the current node // and it has not already been visited if (adj[start][i] == 1 && (!visited[i])) { dfs(i, visited); } } } Shortest Path Representing a directed graph Adjacency list space: O(V + E) Adjacency matrix space: O(V^2) Bellman-Ford Running time: O(EV) Stops after one entire iteration with no changes to estimates Invariant: Let T be a shortest path tree of graph G rooted at source S After iteration j, if u is j hops from s on tree T, then est[u] = distance(s, u) Description: Maintain an estimate of infinity for every node Update estimates with minimum of sum of edges Special issues: If negative weight-cycle: impossible Use Bellman-Ford to detect negative weight cycle (v + 1)th relaxing still changes an estimate If all weights are the same, use BFS void BellmanFord(Graph graph, int src) { int V = graph.V; // number of vertices int E = graph.E; // number of edges int dist[] = new int[V]; // Step 1: Initialize distances from src to all other vertices as INFINITE for (int i = 0; i < V; ++i) { dist[i] = Integer.MAX_VALUE; } dist[src] = 0; // Step 2: For every vertex, visit all edges for (int i = 1; i < V; ++i) { for (int j = 0; j < E; ++j) { // Edge goes from u to v int u = graph.edge[j].src; int v = graph.edge[j].dest; int weight = graph.edge[j].weight; if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; } } } // Step 3: check for negative-weight cycles. Guarantees shortest distances if graph // doesn't contain negative weight cycle. If we get a shorter path, then there is a cycle. for (int j = 0; j < E; ++j) { int u = graph.edge[j].src; int v = graph.edge[j].dest; int weight = graph.edge[j].weight; if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) { System.out.println(\"Graph contains negative weight cycle\"); return; } } printArr(dist, V); } Dijkstra's Algorithm No negative weight edges Description: Maintain distance estimate for every node Add neighbours and their distances into priority queue Remove node with smallest distance, visit its neighbours Done when priority queue is empty Final node will have its shortest distance static class iPair { int first, second; iPair(int first, int second) { this.first = first; this.second = second; } } void shortestPath(int src, int[][] graph) { // Sets up priority queue that compares distance of nodes, shorter distance first PriorityQueue<iPair> pq = new PriorityQueue<>(V, Comparator.comparingInt(o -> o.second)); int[] dist = new int[V]; Arrays.fill(dist, Integer.MAX_VALUE); pq.add(new iPair(0, src)); dist[src] = 0; while (!pq.isEmpty()) { // u is the value of the node with minimum distance int u = pq.poll().first; // for all neighbour of u for (int[] neighbour : graph[u]) { iPair v = new iPair(neighbour[0], neighbour[1]); int newDistance = dist[u] + v.second; if (dist[v.first] > newDistance) { dist[v.first] = newDistance; pq.add(new iPair(v.first, dist[v.first])); } } } for (int i = 0; i < V; i++) { System.out.println(i + dist[i]); } } Using AVL Tree priority queue Running time: O(E logV) insert: O(logn) deleteMin: O(logn) decreaseKey: O(logn) contains(key): O(1) Performance Minimum Spanning Trees A spanning tree with minimum weight Properties: No cycles If you cut an MST, the two pieces are both MSTs For every cycle, the maximum weight edge is not in the MST For every partition of the nodes, the minimum weight edge across the cut is in the MST For every vertex, the minimum outgoing edge is always in the MST (not true for maximum) Prim's Algorithm Continually pick the smallest edge of every node visited Using AVL tree for priority queue: Running time: O(E log V) class Pair implements Comparable<Pair> { int v; int wt; Pair(int v, int wt) { this.v = v; this.wt = wt; } public int compareTo(Pair that) { return this.wt - that.wt; } } static int spanningTree(int V, int E, int edges[][]) { ArrayList<ArrayList<Pair>> adj = new ArrayList<>(); for(int i = 0; i < V; i++) { adj.add(new ArrayList<Pair>()); } for(int i = 0; i < edges.length; i++) { int u = edges[i][0]; // from node u int v = edges[i][1]; // to node v int wt = edges[i][2]; // of weight wt // Add all edges into adj adj.get(u).add(new Pair(v,wt)); adj.get(v).add(new Pair(u,wt)); } PriorityQueue<Pair> pq = new PriorityQueue<Pair>(); pq.add(new Pair(0,0)); int[] vis = new int[V]; int s = 0; while (!pq.isEmpty()) { Pair node = pq.poll(); int v = node.v; // curr node's value int wt = node.wt; // curr node's weight if (vis[v] == 1) { continue; // if node is visited, skip } // node was not visited before s += wt; vis[v] = 1; for(Pair it : adj.get(v)) { if(vis[it.v] == 0) { pq.add(new Pair(it.v, it.wt)); } } } return s; } Kruskal's Algorithm Sort all edges by weight, take all the minimum edges as long as there are no cycles Running time: O(E logV) static class Subset { int parent, rank; public Subset(int parent, int rank) { this.parent = parent; this.rank = rank; } } static class Edge { int src, dest, weight; public Edge(int src, int dest, int weight) { this.src = src; this.dest = dest; this.weight = weight; } } private static int findRoot(Subset[] subsets, int i) { if (subsets[i].parent == i) { return subsets[i].parent; } subsets[i].parent = findRoot(subsets, subsets[i].parent); return subsets[i].parent; } private static void union(Subset[] subsets, int x, int y) { int rootX = findRoot(subsets, x); int rootY = findRoot(subsets, y); if (subsets[rootY].rank < subsets[rootX].rank) { subsets[rootY].parent = rootX; } else if (subsets[rootX].rank < subsets[rootY].rank) { subsets[rootX].parent = rootY; } else { subsets[rootY].parent = rootX; subsets[rootX].rank++; } } private static void kruskals(int V, List<Edge> edges) { int j = 0; int noOfEdges = 0; Subset subsets[] = new Subset[V]; Edge results[] = new Edge[V]; // Create V subsets with single elements for (int i = 0; i < V; i++) { subsets[i] = new Subset(i, 0); } while (noOfEdges < V - 1) { // Edges are sorted in ascending order // Pick the smallest edge Edge nextEdge = edges.get(j); int x = findRoot(subsets, nextEdge.src); int y = findRoot(subsets, nextEdge.dest); // If cycle, root is the same if (x != y) { results[noOfEdges] = nextEdge; union(subsets, x, y); noOfEdges++; } j++; } int minCost = 0; for (int i = 0; i < noOfEdges; i++) { System.out.println(results[i].src + \" -- \" + results[i].dest + \" == \" + results[i].weight); minCost += results[i].weight; } System.out.println(\"Total cost of MST: \" + minCost); } Dynamic Programming Bottom up Solve smallest problems Combine smaller problems Solve root problem Top down Start at root and recurse Recurse Solve and memoize Topological Sort Using DFS to find cycles and add to stack Verifies if the graph given is a directed acyclic graph (DAG) class Solution { HashMap<Integer, LinkedList<Integer>> adj = new HashMap<>(); HashMap<Integer, Boolean> visited = new HashMap<>(); Stack<Integer> stack = new Stack<>(); boolean isImpossible = false; public void addEdge(int v, int w) { adj.putIfAbsent(v, new LinkedList<>()); adj.putIfAbsent(w, new LinkedList<>()); adj.get(v).add(w); } private void dfsHelper(Integer v, HashMap<Integer, Boolean> visited1) { visited.put(v, true); visited1.put(v, true); // Traverse neighbours for (Integer i: adj.get(v)) { if (visited1.containsKey(i)) { isImpossible = true; // there is a cycle break; } if (!visited.get(i)) { dfsHelper(i, visited1); } } visited1.remove(v); stack.push(v); } public int[] findOrder(int numCourses, int[][] prerequisites) { int[] res = new int[numCourses]; Arrays.setAll(res, i -> i); if (prerequisites.length == 0) { return res; } // Add all edges into graph adj for (int[] prerequisite : prerequisites) { addEdge(prerequisite[1], prerequisite[0]); } // Set all keys to visited = false for (Integer key: adj.keySet()) { visited.put(key, false); } // Start DFS for (Integer key: adj.keySet()) { HashMap<Integer, Boolean> visited1 = new HashMap<>(); if (visited.get(key) == false) { dfsHelper(key, visited1); } } if (isImpossible) { return new int[0]; } HashMap<Integer, Integer> hm = new HashMap<>(); for (int i = 0; i < numCourses; i++) { hm.put(i, i); } // Add sorted courses into array int n = stack.size(); for (int i = 0; i < n; i++) { int course = stack.pop(); res[i] = course; hm.remove(course); } // Fill in the rest of the array with the missing courses int[] left = hm.keySet().stream().mapToInt(Integer::intValue).toArray(); int i1 = 0; int i2 = n; while (i1 < left.length && n < numCourses) { res[i2] = left[i1]; i1++; i2++; } return res; } }","title":"Data Structures and Algorithm"},{"location":"dsa-notes/dsa-notes/#data-structures-and-algorithm","text":"Data Structures and Algorithm Recurrence Relations Binary Search Peak Finding Sorting BubbleSort SelectionSort InsertionSort MergeSort QuickSort Partition QuickSelect Trees Binary Search Trees Height Search Insert Traversals Inorder Traversal Preorder Traversal Postorder Traversal Delete Balanced Trees AVL Insert Delete Tries Dynamic Order Statistics Interval Trees Insert Interval Search 1D Range Trees Query 2D Range Trees Priority Queue Binary (Max) Heaps Insert DecreaseKey Delete Heap vs AVL Tree HeapSort Disjoint Set Quick Find: using an int[] componentId Quick Union: using an int[] parent Weighted Union Weighted Union with Path Compression Hashing Direct Access Table Chaining Open Addressing Resizing Table Graph Breadth-First Search Depth-First Search Shortest Path Bellman-Ford Dijkstra's Algorithm Minimum Spanning Trees Prim's Algorithm Kruskal's Algorithm Dynamic Programming Topological Sort","title":"Data Structures and Algorithm"},{"location":"dsa-notes/dsa-notes/#recurrence-relations","text":"T(n) = T(n-1) + O(1) = O(n) T(n) = T(n/2) + O(1) = O(logn) T(n) = T(n-1) + O(n) = O(n^2) T(n) = T(n-1) + O(nk) = O(n^(k+1)) T(n) = 2T(n/2) + O(n) = O(nlogn) T(n) = T(n/2) + O(n) = O(n) T(n) = 2T(n/2) + O(1) = O(n) T(n) = 2T(n-1) + O(1) = O(2^n)","title":"Recurrence Relations"},{"location":"dsa-notes/dsa-notes/#binary-search","text":"Time complexity: O(logn) Preconditions: Array is of size n Array is sorted Postconditions: If element is in array: A[left] = key Loop invariant: A[left] <= key <= A[right] (right - left) <= n/2^k in iteration k public int search(int A[], int key, int n) { int left = 0; int right = n - 1; while (left < right) { // int mid = (left + right) / 2 can lead to integer overflow int mid = left + (right - left) / 2; if (key <= A[mid]) { right = mid; } else { left = mid + 1; } } return (A[left] == key ? left : -1); }","title":"Binary Search"},{"location":"dsa-notes/dsa-notes/#peak-finding","text":"Output a local maximum in A, where A[i - 1] <= A[i] and A[i + 1] <= A[i] Time complexity: O(logn) Invariant: If we recuse in the right half, then there exists a peak in the right half There exists a peak in the range [begin, end] Every peak in [begin, end] is a peak in [1, n] T(n) = T(n/2) + \u03b8(1) = O(logn) public int findPeak(int A[], int n) { // if right of mid is larger, recurse on right if (A[n / 2 + 1] > A[n / 2]) { return findPeak(Arrays.copyOfRange(A, n / 2 + 1, n + 1), n / 2) // if left of mid is larger, recurse on left } else if (A[n / 2 - 1] > A[n / 2]) { return findPeak(Arrays.copyOfRange(A, 0, n / 2), n / 2) } else { return n / 2; } }","title":"Peak Finding"},{"location":"dsa-notes/dsa-notes/#sorting","text":"","title":"Sorting"},{"location":"dsa-notes/dsa-notes/#bubblesort","text":"Invariant: At the end of iteration i, the biggest j items are correctly sorted in the final j positions of the array. Best: O(n), when array is already sorted Worst: O(n^2) , when array is reverse sorted Stable Description: For n loops, if A[j] > A[j + 1], swap(A[j], A[j + 1]) void bubbleSort(int arr[], int n) { int i, j, temp; boolean swapped; for (i = 0; i < n - 1; i++) { swapped = false; for (j = 0; j < n - i - 1; j++) { if (arr[j] > arr[j + 1]) { // Swap arr[j] and arr[j+1] temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; swapped = true; } } // If no two elements were // swapped by inner loop, then break if (swapped == false) break; } }","title":"BubbleSort"},{"location":"dsa-notes/dsa-notes/#selectionsort","text":"Invariant: At the end of iteration j: the smallest j items are correctly sorted in the first j positions of the array. Best: O(n^2) Worst: O(n^2) Not stable Description: For n loops, find minimum element A[j] in A[j..n], swap(A[j], A[k]) void selectionSort(int arr[], int n) { int min_idx = 0; // One by one move boundary of unsorted subarray for (int i = 0; i < n - 1; i++) { // Find the minimum element in unsorted array min_idx = i; for (int j = i + 1; j < n; j++) { if (arr[j] < arr[min_idx]) min_idx = j; } // Swap the found minimum element with the first element if (min_idx != i) swap(arr[min_idx], arr[i]); } }","title":"SelectionSort"},{"location":"dsa-notes/dsa-notes/#insertionsort","text":"Invariant: At the end of iteration j: the first j items in the array are in sorted order. Best: O(n), when array is already sorted Worst: O(n^2) , when array is reverse sorted Stable Description: For n loops, insert key into the sorted array A[1 .. j - 1] void insertionSort(int arr[]) { int n = arr.length; for (int i = 1; i < n; ++i) { int key = arr[i]; int j = i - 1; /* Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position */ while (j >= 0 && arr[j] > key) { arr[j + 1] = arr[j]; j = j - 1; } arr[j + 1] = key; } }","title":"InsertionSort"},{"location":"dsa-notes/dsa-notes/#mergesort","text":"Best: O(n logn) Worst: O(n logn) Stable Memory: O(n logn) Description: Divide: split array into two halves Recurse: sort the two halves Combine: merge the two sorted halves Use InsertionSort instead for n < 1024 void merge(int arr[], int l, int m, int r) { // Find sizes of two subarrays to be merged int n1 = m - l + 1; int n2 = r - m; // Create temp arrays int L[] = new int[n1]; int R[] = new int[n2]; // Copy data to temp arrays for (int i = 0; i < n1; ++i) L[i] = arr[l + i]; for (int j = 0; j < n2; ++j) R[j] = arr[m + 1 + j]; // Merge the temp arrays // Initial indices of first and second subarrays int i = 0, j = 0; // Initial index of merged subarray array int k = l; while (i < n1 && j < n2) { if (L[i] <= R[j]) { arr[k] = L[i]; i++; } else { arr[k] = R[j]; j++; } k++; } // Copy remaining elements of L[] if any while (i < n1) { arr[k] = L[i]; i++; k++; } // Copy remaining elements of R[] if any while (j < n2) { arr[k] = R[j]; j++; k++; } } void mergeSort(int arr[], int l, int r) { if (l < r) { // Find the middle point int m = l + (r - l) / 2; // Sort first and second halves mergeSort(arr, l, m); mergeSort(arr, m + 1, r); // Merge the sorted halves merge(arr, l, m, r); } }","title":"MergeSort"},{"location":"dsa-notes/dsa-notes/#quicksort","text":"Invariant: At the end of every loop iteration, For every i < low: B[i] < pivot For every j > high: B[j] > pivot Best: O(n logn) , when median element is chosen as pivot Worst: O(n^2) , when first element is chosen as pivot/ all elements are the same Not stable Description: Divide: Partition the array into two sub-arrays around a pivot x such that elements in lower subarray \u2264 x \u2264 elements in upper sub-array. Conquer: Recursively sort the two sub-arrays. Combine: Trivial, do nothing. void quickSort(int[] arr, int low, int high) { if (low < high) { // pi is partitioning index, arr[pi] // is now at right place int pi = partition(arr, low, high); // Separately sort elements before // partition and after partition quickSort(arr, low, pi - 1); quickSort(arr, pi + 1, high); } }","title":"QuickSort"},{"location":"dsa-notes/dsa-notes/#partition","text":"Invariant: A[high] > pivot at the end of each loop At the end of every loop iteration For all i >= high, A[i] > pivot For all 1 < j < low, A[j] < pivot Time complexity: O(n) int partition(int[] arr, int low, int high) { // Choosing the pivot int pivot = arr[high]; // Index of smaller element and indicates // the right position of pivot found so far int i = (low - 1); for (int j = low; j <= high - 1; j++) { // If current element is smaller than the pivot if (arr[j] < pivot) { // Increment index of smaller element i++; swap(arr, i, j); } } swap(arr, i + 1, high); return (i + 1); }","title":"Partition"},{"location":"dsa-notes/dsa-notes/#quickselect","text":"Invariant: After partioning, arr[partition] is now at right place Time complexity: O(n) Description: Find the k-th smallest element in an unordered list partition the array if partition is at position k, the partition is the k-th smallest element else continue searching in the correct half // ASSUMPTION: all elements in arr[] are distinct int kthSmallest(int[] arr, int low, int high, int k) { // find the partition int partition = partition(arr, low, high); // if partition value is equal to the kth position, return value at k if (partition == k - 1) { return arr[partition]; } // if partition value is less than kth position, search right side of the array else if (partition < k - 1) { return kthSmallest(arr, partition + 1, high, k); } // if partition value is more than kth position, search left side of the array else { return kthSmallest(arr, low, partition - 1, k); } }","title":"QuickSelect"},{"location":"dsa-notes/dsa-notes/#trees","text":"","title":"Trees"},{"location":"dsa-notes/dsa-notes/#binary-search-trees","text":"All in left sub-tree < key < all in right sub-tree","title":"Binary Search Trees"},{"location":"dsa-notes/dsa-notes/#height","text":"Number of edges on longest path from root to leaf h(v) = 0 (if v is a leaf) h(v) = max(h(v.left), h(v.right)) + 1 Time complexity: O(logn) int height() { int leftHeight = -1; int rightHeight = -1; if (leftTree != null) { leftHeight = leftTree.height(); } if (rightTree != null) { rightHeight = rightTree.height(); } return max(leftHeight, rightHeight) + 1; }","title":"Height"},{"location":"dsa-notes/dsa-notes/#search","text":"Worst case: O(n) , (when n = h) Time complexity: O(h) searchMax() TreeNode searchMax() { if (rightTree != null) { return rightTree.searchMax(); } else { return this; } } searchMin() TreeNode searchMin() { if (leftTree != null) { return leftTree.searchMin(); } else { return this; } } search(int queryKey) public TreeNode search(int queryKey){ if (queryKey < key) { if (leftTree != null) { return leftTree.search(key); } else { return null; } } else if (queryKey > key) { if (rightTree != null) { return rightTree.search(key); } else { return null; } } else { return this; // Key is here! } }","title":"Search"},{"location":"dsa-notes/dsa-notes/#insert","text":"void insert(int insKey, int intValue) { if (insKey < key) { if (leftTree != null) { leftTree.insert(insKey); } else { leftTree = new TreeNode(insKey,insValue) } } else if (insKey > key) { if (rightTree != null) { rightTree.insert(insKey); } else { rightTree = new TreeNode(insKey, insValue); } } else { return; // Key is already in the tree! } }","title":"Insert"},{"location":"dsa-notes/dsa-notes/#traversals","text":"","title":"Traversals"},{"location":"dsa-notes/dsa-notes/#inorder-traversal","text":"Left, self, right Running time: O(n) void inOrder(Node node) { if (node == null) return; // First recur on left child inOrder(node.left); // Then print the data of node System.out.print(node.key + \" \"); // Now recur on right child inOrder(node.right); }","title":"Inorder Traversal"},{"location":"dsa-notes/dsa-notes/#preorder-traversal","text":"Self, left, right Running time: O(n) void preOrder(Node node) { if (node == null) return; // Print the data of node System.out.print(node.key + \" \"); // Then recur on left child preOrder(node.left); // Now recur on right child preOrder(node.right); }","title":"Preorder Traversal"},{"location":"dsa-notes/dsa-notes/#postorder-traversal","text":"Left, right, self Running time: O(n) void postOrder(Node node) { if (node == null) return; // First recur on left child postOrder(node.left); // Then recur on right child postOrder(node.right); // Now print the data of node System.out.print(node.key + \" \"); }","title":"Postorder Traversal"},{"location":"dsa-notes/dsa-notes/#delete","text":"Successor Running time: O(h) Idea: Search for key in the tree. If (result > key), then return result. If (result <= key), then search for successor of result. Case 1: node has a right child Case 2: node has no right child public TreeNode successor() { if (rightTree != null) { return rightTree.searchMin(); } TreeNode parent = parentTree; TreeNode child = this; while ((parent != null) && (child == parent.rightTree)) { child = parent; parent = child.parentTree; } return parent; } Delete Running time: O(h) Case 1: no children Remove v Case 2: 1 child Remove v Connect child(v) to parent(v) Case 3: 2 children x = successor(v) Delete(x) Remove v Connect x to left(v), right(v), parent(v)","title":"Delete"},{"location":"dsa-notes/dsa-notes/#balanced-trees","text":"BST is balanced if h = O(logn) All operations run in O(logn) time Maxmimum height: h < 2logn Mininimum nodes: n > 2^(h/2) In every node v, store height (augment) On insert and delete, update height: height = max(left.height, right.height) + 1 Define Invariant A node v is height-balanced if |v.left.height - v.right.height| <= 1 A BST is height-balanced if every node is height-balanced Maintain balance // assume v has left != null void rightRotate(TreeNode v) { TreeNode w = v.left; w.parent = v.parent; v.parent = w; v.left = w.right; w.right = v; } // assume v has right != null void leftRotate(TreeNode v) { TreeNode w = v.right; w.parent = v.parent; v.parent = w; v.right = w.left; w.left = v; } If v is out of balanced and left-heavy: Case 1: v.left is balanced -> rightRotate(v) Case 2: v.left is left-heavy -> rightRotate(v) Case 3: v.left is right-heavy -> leftRotate(v.left), rightRotate(v) If v is out of balanced and right-heavy: Case 1: v.right is balanced -> leftRotate(v) Case 2: v.right is left-heavy -> leftRotate(v) Case 3: v.right is right-heavy -> rightRotate(v.right), leftRotate(v) import java.util.TreeSet; TreeSet<IntegerNode> leftHalf; TreeSet<IntegerNode> rightHalf; void rebalance() { int leftSize = this.leftHalf.size(); int rightSize = this.rightHalf.size(); int diff = Math.abs(leftSize - rightSize); if (diff > 1) { if (leftSize > rightSize) { // Left is bigger, move the biggest item to right this.rightHalf.add(this.leftHalf.pollLast()); } else { // Right is bigger, move the smallest item to left this.leftHalf.add(this.rightHalf.pollFirst()); } } }","title":"Balanced Trees"},{"location":"dsa-notes/dsa-notes/#avl","text":"","title":"AVL"},{"location":"dsa-notes/dsa-notes/#insert_1","text":"Summary: Insert key in BST Walk up tree: At every step, check for balance If out-of-balance, use rotations to rebalance and return Key observation: Only need to fix lowest out-of-balance node Only need at most two rotations to fix","title":"Insert"},{"location":"dsa-notes/dsa-notes/#delete_1","text":"If v has two children, swap it with its successor Delete node v from binary tree (and reconnect children) For every ancestor of the deleted node: Check if it is height-balanced If not, perform a rotation Continue to the root Summary: Delete key from BST Walk up tree: At every step, check for balance If out-of-balance, use rotations to rebalance continue to root Key observation: Needs at most O(logn) rotations import java.util.*; import java.io.*; class Node { int key, height; Node left, right; Node (int d) { key = d; height = 1; } } class AVLTree { Node root; int height (Node N) { if (N == null) return 0; return N.height; } int max (int a, int b) { return (a > b) ? a : b; } Node rightRotate (Node y) { Node x = y.left; Node T2 = x.right; x.right = y; y.left = T2; y.height = max (height (y.left), height (y.right)) + 1; x.height = max (height (x.left), height (x.right)) + 1; return x; } Node leftRotate (Node x) { Node y = x.right; Node T2 = y.left; y.left = x; x.right = T2; x.height = max (height (x.left), height (x.right)) + 1; y.height = max (height (y.left), height (y.right)) + 1; return y; } int getBalance (Node N) { if (N == null) return 0; return height (N.left) - height (N.right); } Node insert (Node node, int key) { if (node == null) return (new Node (key)); if (key < node.key) node.left = insert (node.left, key); else if (key > node.key) node.right = insert (node.right, key); else return node; node.height = 1 + max (height (node.left), height (node.right)); int balance = getBalance (node); if (balance > 1 && key < node.left.key) return rightRotate (node); if (balance < -1 && key > node.right.key) return leftRotate (node); if (balance > 1 && key > node.left.key) { node.left = leftRotate (node.left); return rightRotate (node); } if (balance < -1 && key < node.right.key) { node.right = rightRotate (node.right); return leftRotate (node); } return node; } }","title":"Delete"},{"location":"dsa-notes/dsa-notes/#tries","text":"Cost of comparing two strings in a tree: O(hL) Cost in trie: O(L) Space for storing a try: O(size of text * overhead)","title":"Tries"},{"location":"dsa-notes/dsa-notes/#dynamic-order-statistics","text":"Select(k) : finds the node with rank k // augmented tree with weight // O(logn) Node select(k) { rank = m_left.weight + 1; if (k == rank) { return v; } else if (k < rank) { return m_left.select(k); } else if (k > rank) { return m_right.select(k\u2013rank); } } // in-order traversal method // O(n) Node kthSmallest(int k) { Result result = new Result(0, null); inOrderTraversal(root, k, result); return result.result; } void inOrderTraversal(Node node, int k, Result result) { if (node == null || result.count >= k) { return; } inOrderTraversal(node.left, k, result); result.count++; if (result.count == k) { result.result = node; return; } inOrderTraversal(node.right, k, result); } class Result { int count; Node result; Result(int count, Node result) { this.count = count; this.result = result; } } Rank(v) : computes the rank of a node v // augmented tree with weight // O(logn) int rank(TreeNode node) { rank = node.left.weight + 1; while (node != null) { if (node.parent.left == node) { continue; } else { rank += node.parent.left.weight + 1; } node = node.parent; } return rank; } // recursion method // worst case: O(n) int rank(TreeNode node, int x) { if (node == null) { return 0; } if (node.value <= x) { return 1 + rank(node.left, x) + rank(node.right,x); } else { return rank(node.left, x) } }","title":"Dynamic Order Statistics"},{"location":"dsa-notes/dsa-notes/#interval-trees","text":"Augment tree with maximum endpoint in subtree class Node { int[] interval; int maxEnd; Node left, right; int height; Node(int[] interval) { this.interval = interval; this.maxEnd = interval[1]; this.left = this.right = null; this.height = 1; } }","title":"Interval Trees"},{"location":"dsa-notes/dsa-notes/#insert_2","text":"class IntervalTree { private int height(Node node) { return (node == null) ? 0 : node.height; } private int maxEnd(Node node) { return (node == null) ? Integer.MIN_VALUE : node.maxEnd; } private int getBalance(Node node) { return (node == null) ? 0 : height(node.left) - height(node.right); } private Node insert(Node root, int[] interval) { if (root == null) { return new Node(interval); } if (interval[0] < root.interval[0]) { root.left = insert(root.left, interval); } else { root.right = insert(root.right, interval); } root.height = Math.max(height(root.left), height(root.right)) + 1; root.maxEnd = Math.max(root.interval[1], Math.max(maxEnd(root.left), maxEnd(root.right))); int balance = getBalance(root); // Left Heavy if (balance > 1) { if (interval[0] < root.left.interval[0]) { return rotateRight(root); } else { root.left = rotateLeft(root.left); return rotateRight(root); } } // Right Heavy if (balance < -1) { if (interval[0] > root.right.interval[0]) { return rotateLeft(root); } else { root.right = rotateRight(root.right); return rotateLeft(root); } } return root; } }","title":"Insert"},{"location":"dsa-notes/dsa-notes/#interval-search","text":"Find interval containing x Running time: O(logn) boolean isInInterval(Node c, int x) { return x >= c.interval[0] && x <= c.interval[1]; } int[] intervalSearch(int x) { Node c = root; while (c != null && !isInInterval(c, x)) { if (c.left == null) { c = c.right; } else if (x > c.left.maxEnd) { c = c.right; } else { c = c.left; } } return c.interval; } All-Overlaps: List all intervals that overlap with point Running time if there are k overlapping intervals: O(k logn) Repeat until no more intervals: Search for interval. Add to list. Delete interval. Repeat for all intervals on list: Add interval back to tree.","title":"Interval Search"},{"location":"dsa-notes/dsa-notes/#1d-range-trees","text":"Strategy: Use a binary search tree. Store all points in the leaves of the tree. (Internal nodes store only copies.) Each internal node v stores the MAX of any leaf in the left sub-tree.","title":"1D Range Trees"},{"location":"dsa-notes/dsa-notes/#query","text":"Invariant: The search interval for a left-traversal at node v includes the maximum item in the subtree rooted at v. Algorithm: Find split node, takes O(logn) Do left traversal Do right traversal Query time complexity: O(k + logn), where k is number of points found Preprocessing (buildtree) time complexity: O(n logn) Total space complexity: O(n) Node FindSplit(int low, int high) { Node v = root; done = false; while (!done) { if (high <= v.key) { v = v.left; } else if (low > v.key) { v = v.right; } else { done = true } } return v; } // LeftTraversal either: // 1. Output all right sub-tree and recurse left. // 2. Recurse right. void LeftTraversal(Node v, int low, int high) { boolean isInRange = low <= v.key; boolean isLeafNode = v.left == null && v.right == null; if (isLeafNode && isInRange) { System.out.println(v.key); } if (isInRange) { // if in range, take the all of right subtree's leafs AllLeafTraversal(v.right); LeftTraversal(v.left, low, high); } else { LeftTraversal(v.right, low, high); } } void RightTraversal(Node v, int low, int high) { boolean isInRange = v.key <= high; boolean isLeafNode = v.left == null && v.right == null; if (isLeafNode && isInRange) { System.out.println(v.key); } if (isInRange) { // if in range, take the all of left subtree's leafs AllLeafTraversal(v.left); RightTraversal(v.right, low, high); } else { RightTraversal(v.left, low, high); } } void AllLeafTraversal(Node v) { if (v == null) { return; } // only leaf nodes are printed if (v.left == null && v.right == null) { System.out.println(v.key); } AllLeafTraversal(v.left); AllLeafTraversal(v.right); } void Query(low, high) { Node v = FindSplit(low, high); LeftTraversal(v.left, low, high); RightTraversal(v.right, low, high); }","title":"Query"},{"location":"dsa-notes/dsa-notes/#2d-range-trees","text":"Build an x-tree using only x-coordinates. For every node in the x-tree, build a y-tree out of nodes in subtree using only y-coordinates. Query time: O((logn)^2 + k) O(logn) to find split node O(logn) recursing steps O(logn) y-tree-searches of cost O(logn) O(k) enumerating output Space complexity: O(n logn) Each point appears in at most one y-tree per level There are O(log n) levels Query cost: O((logn)^d + k) buildTree cost: O(n (logn)^d-1) Space: O(n (logn)^d-1)","title":"2D Range Trees"},{"location":"dsa-notes/dsa-notes/#priority-queue","text":"Return Type Operation Description void insert(Key k, Priority p) insert k with priority p Data extractMin() remove key with min. priority void decreaseKey(Key k, Priority p) reduce the priority of key k to priority p boolean contains(Key k) whether queue contains key k boolean isEmpty() whether queue is empty Sorted array Insert: O(n) extractMax: O(1) Unsorted array insert: O(1) extractMax: O(n) AVL tree (indexed by priority) insert: O(logn) extractMax: O(logn) AVL tree and dictionary contains: O(1) decreaseKey: O(logn)","title":"Priority Queue"},{"location":"dsa-notes/dsa-notes/#binary-max-heaps","text":"Heap ordering: priority[parent] >= priority[child] Complete binary tree Every level is full, except possibly the last All nodes are as far left as possible Height: O(logn) (maximum height is floor(logn)) Operations: O(logn) Implements a max priority queue Return Type Operation Description void insert(Key k, Priority p) insert k with priority p Data extractMax() remove key with max priority void increaseKey(Key k, Priority p) increase the priority of key k to priority p void decreaseKey(Key k, Priority p) reduce the priority of key k to priority p Data delete(Key k) delete k from heap left(x) = 2 * x + 1 right(x) = 2 * x + 2 parent(x) = floor((x - 1) / 2) Where x is the position of the node in the array","title":"Binary (Max) Heaps"},{"location":"dsa-notes/dsa-notes/#insert_3","text":"Add leaf of new node at leftmost position Bubble up (swap with parent) until condition priority[parent] >= priority[child] fulfilled bubbleUp(Node v) { while (v != null) { if (priority(v) > priority(parent(v))) { swap(v, parent(v)); } else { return; } v = parent(v); } } insert(Priority p, Key k) { Node v = tree.insert(p, k); bubbleUp(v); }","title":"Insert"},{"location":"dsa-notes/dsa-notes/#decreasekey","text":"Update priority Bubble down (swap with child that has higher priority) bubbleDown(Node v) { while (!isLeaf(v)) { leftP = priority(left(v)); rightP = priority(right(v)); maxP = max(leftP, rightP, priority(v)); if (leftP == max) { swap(v, left(v)); v = left(v); } else if (rightP == max) { swap(v, right(v)); v = right(v); } else { return; } } }","title":"DecreaseKey"},{"location":"dsa-notes/dsa-notes/#delete_2","text":"Swap deleted node with last node (which is last element in array) Remove last node Bubble down swapped node ExtractMax: delete(root);","title":"Delete"},{"location":"dsa-notes/dsa-notes/#heap-vs-avl-tree","text":"Same asymptotic cost for operations Faster real cost (no constant factors) Simpler: no rotations Slightly better concurrency","title":"Heap vs AVL Tree"},{"location":"dsa-notes/dsa-notes/#heapsort","text":"Running time: O(n logn) In-place Deterministic, and will always take O(n logn) Faster than MergeSort, a little slower than QuickSort Not stable Unsorted list --> heap (running time: O(n)), specifically 2 * O(n) Base case: each leaf is a heap Recursion: siblings + parent nodes = heap (bubbleDown) // int[] A = array of unsorted integers for (int i = n - 1; i >= 0; i--) { bubbleDown(i, A); // O(height), but more than n/2 of nodes are leaves with height = 0 } Heap --> sorted list () (running time: O(n logn)) Fill array from last position to first position, by recursively calling extractMax() //int[] A = array stored as a heap for (int i = n - 1; i >= 0; i--) { int value = extractMax(A); //O(logn) A[i] = value; }","title":"HeapSort"},{"location":"dsa-notes/dsa-notes/#disjoint-set","text":"Determine if objects are connected","title":"Disjoint Set"},{"location":"dsa-notes/dsa-notes/#quick-find-using-an-int-componentid","text":"Store component identifier of each object Find: O(1) Finds whether p and q are connected boolean find(int p, int q) { return(componentId[p] == componentId[q]); } Union: O(n) Make p and q have the same componentId Traverse the component identifier array: if id = q's id, update to be p's id void union(int p, int q) { updateComponent = componentId[q]; for (int i=0; i<componentId.length; i++) { if (componentId[i] == updateComponent) { componentId[i] = componentId[p]; } } }","title":"Quick Find: using an int[] componentId"},{"location":"dsa-notes/dsa-notes/#quick-union-using-an-int-parent","text":"Two objects are connected if they are part of the same tree Find: O(n) Traverse up the tree from given node, to find parent If final parents are the same, they are connected boolean find(int p, int q) { while (parent[p] != p) { p = parent[p]; } while (parent[q] != q) { q = parent[q]; } return (p == q); } Union: O(n), height of tree can be n Traverse up the tree from given node, to find parent Set parent of p to be q void union(int p, int q) { while (parent[p] != p) { p = parent[p]; } while (parent[q] != q) { q = parent[q]; } parent[p] = q; }","title":"Quick Union: using an int[] parent"},{"location":"dsa-notes/dsa-notes/#weighted-union","text":"Choose the larger element to be the parent during union Maximum depth of tree: O(logn) Running time of find : O(logn) Running time of union : O(logn) union(int p, int q) { while (parent[p] !=p) { p = parent[p]; } while (parent[q] !=q) { q = parent[q]; } if (size[p] > size[q]) { parent[q] = p; // Link q to p size[p] = size[p] + size[q]; } else { parent[p] = q; // Link p to q size[q] = size[p] + size[q]; } }","title":"Weighted Union"},{"location":"dsa-notes/dsa-notes/#weighted-union-with-path-compression","text":"After finding root, set the parent of each traversed node to the root Tree height is compressed // Takes O(logn) time findRoot(int p) { root = p; while (parent[root] != root) { root = parent[root]; } while (parent[p] != p) { temp = parent[p]; parent[p] = root; p = temp; } return root; } union(int p, int q) { p = findRoot(p); q = findRoot(q); if (size[p] > size[q]) { parent[q] = p; // Link q to p size[p] = size[p] + size[q]; } else { parent[p] = q; // Link p to q size[q] = size[p] + size[q]; } } Starting from empty, any sequence of m union/find operations on n objects takes: O(n + m\u03b1(m, n))time. Path compression is helpful with more union/ find operations First operation will still take the same amount of time (+ path compression for future operations) \u03b1 = ackermann function (between O(1) and O(logn)) Running time of find : \u03b1(m, n) Running time of union : \u03b1(m, n)","title":"Weighted Union with Path Compression"},{"location":"dsa-notes/dsa-notes/#hashing","text":"Implement symbol table with an AVL tree: C(insert) = O(logn); C(search) = O(logn)","title":"Hashing"},{"location":"dsa-notes/dsa-notes/#direct-access-table","text":"Using a table, indexed by keys Insert: O(1), Search: O(1) Space: m buckets Hash function defined to derive key Impossible to choose a hash function with no collisions (pigeonhole principle)","title":"Direct Access Table"},{"location":"dsa-notes/dsa-notes/#chaining","text":"Insert a linked list in the table, indexed by keys Space: O(m + n); table size is m, linked list size is n Insert: O(1 + cost(h)) Worst case search: O(n + cost(h)) (when all keys hash to the same bucket, cost is n) With SUHA, E(search time) = 1 + n/m = O(1) Maximum chain length with SUHA = O(logn) = \u0398(logn / loglogn) Simple uniform hashing assumption (made of the hashing function) Every key is equally likely to map to every bucket Keys are mapped independently P(i'th key is put in bucket j) = 1/m","title":"Chaining"},{"location":"dsa-notes/dsa-notes/#open-addressing","text":"All data directly stored in the table, with one item per slot On collision, probe a sequence of buckets until an empty one is found Delete Set bucket to DELETED , instead of leaving it empty So that search can find an element Properties of good hash function h(key, i) enumerates all possible buckets Simple Uniform Hashing Assumption Linear probing can lead to clusters: O(n) Assuming uniform hashing, E(cost of operations) = 1 / (1 - a) a = n / m Performance degrades badly as a -> 1 Double Hashing Using two hash functions, define a new hash function: h(k, i) = f(k) + i * g(k) mod m","title":"Open Addressing"},{"location":"dsa-notes/dsa-notes/#resizing-table","text":"Cost of resize from m to m + 1 Cost of double size: O(n) (done when the table is full) Cost of inserting n items + resizing: O(n) Most insertions: O(1) Average cost: O(1) Half the table size when table is 3/4 empty Cost of squared table size: O(n^2) Cost of inserts: O(n) Deleting elements: O(1 + n/m)","title":"Resizing Table"},{"location":"dsa-notes/dsa-notes/#graph","text":"Diameter: maximum distance between two notes, following the shortest path Special graphs Star: one central node, all edges connect centre to edges; diameter = 2 Clique: complete graph, degree = n - 1; diameter = 1 Line or path: degree = 2; diameter = n - 1 Cycle: degree = 2; diameter = n/2 or n/2 - 1 Bipartite graph: nodes divided into two sets with no edges between nodes in the same set; diameter = n - 1 Memory usage of graph G | | Adjacency List | Adjacency Matrix | | ------------ | -------------- | ---------------- | | Graph (V, E) | O(V + E) | O(V^2) | | Cycle | O(V) | O(V^2) | | Clique | O(V^2) | O(V^2) |","title":"Graph"},{"location":"dsa-notes/dsa-notes/#breadth-first-search","text":"BFS with adjacency list: O(V + E) // With an adjacency list void BFS(int s) { // Mark all the vertices as not visited boolean visited[] = new boolean[V]; // Create a queue for BFS LinkedList<Integer> queue = new LinkedList<Integer>(); // Mark the current node as visited and enqueue it visited[s] = true; queue.add(s); while (queue.size() != 0) { // Dequeue a vertex from queue and print it s = queue.poll(); System.out.print(s + \" \"); // Get all adjacent vertices of the dequeued // vertex s. // If an adjacent has not been visited, // then mark it visited and enqueue it Iterator<Integer> i = adj[s].listIterator(); while (i.hasNext()) { int n = i.next(); if (!visited[n]) { visited[n] = true; queue.add(n); } } } } BFS with adjacency matrix: O(V^2) // With an adjacency matrix void BFS(int start) { // A vertex is not visited more than once // Initializing the vector to false at the beginning boolean[] visited = new boolean[v]; Arrays.fill(visited, false); List<Integer> q = new ArrayList<>(); q.add(start); // Set source as visited visited[start] = true; int vis; while (!q.isEmpty()) { vis = q.get(0); // Print the current node System.out.print(vis + \" \"); q.remove(q.get(0)); // For every adjacent vertex to the current vertex for(int i = 0; i < v; i++) { if (adj[vis][i] == 1 && (!visited[i])) { // Push the adjacent node to the queue q.add(i); visited[i] = true; } } } }","title":"Breadth-First Search"},{"location":"dsa-notes/dsa-notes/#depth-first-search","text":"DFS with adjacency list: O(V + E) // With an adjacency list void DFSUtil(int v, boolean visited[]) { // Mark the current node as visited and print it visited[v] = true; System.out.print(v + \" \"); // Recurse for all adjacent vertices Iterator<Integer> i = adj[v].listIterator(); while (i.hasNext()) { int n = i.next(); if (!visited[n]) DFSUtil(n, visited); } } void DFS(int v) { // Mark all the vertices as // not visited(set as // false by default in java) boolean visited[] = new boolean[V]; // Call the recursive helper // function to print DFS // traversal DFSUtil(v, visited); } DFS with adjacency matrix: O(V^2) // With an adjacency matrix static void dfs(int start, boolean[] visited) { // Print the current node System.out.print(start + \" \"); // Set current node as visited visited[start] = true; // For every node of the graph for (int i = 0; i < adj[start].length; i++) { // If some node is adjacent to the current node // and it has not already been visited if (adj[start][i] == 1 && (!visited[i])) { dfs(i, visited); } } }","title":"Depth-First Search"},{"location":"dsa-notes/dsa-notes/#shortest-path","text":"Representing a directed graph Adjacency list space: O(V + E) Adjacency matrix space: O(V^2)","title":"Shortest Path"},{"location":"dsa-notes/dsa-notes/#bellman-ford","text":"Running time: O(EV) Stops after one entire iteration with no changes to estimates Invariant: Let T be a shortest path tree of graph G rooted at source S After iteration j, if u is j hops from s on tree T, then est[u] = distance(s, u) Description: Maintain an estimate of infinity for every node Update estimates with minimum of sum of edges Special issues: If negative weight-cycle: impossible Use Bellman-Ford to detect negative weight cycle (v + 1)th relaxing still changes an estimate If all weights are the same, use BFS void BellmanFord(Graph graph, int src) { int V = graph.V; // number of vertices int E = graph.E; // number of edges int dist[] = new int[V]; // Step 1: Initialize distances from src to all other vertices as INFINITE for (int i = 0; i < V; ++i) { dist[i] = Integer.MAX_VALUE; } dist[src] = 0; // Step 2: For every vertex, visit all edges for (int i = 1; i < V; ++i) { for (int j = 0; j < E; ++j) { // Edge goes from u to v int u = graph.edge[j].src; int v = graph.edge[j].dest; int weight = graph.edge[j].weight; if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) { dist[v] = dist[u] + weight; } } } // Step 3: check for negative-weight cycles. Guarantees shortest distances if graph // doesn't contain negative weight cycle. If we get a shorter path, then there is a cycle. for (int j = 0; j < E; ++j) { int u = graph.edge[j].src; int v = graph.edge[j].dest; int weight = graph.edge[j].weight; if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) { System.out.println(\"Graph contains negative weight cycle\"); return; } } printArr(dist, V); }","title":"Bellman-Ford"},{"location":"dsa-notes/dsa-notes/#dijkstras-algorithm","text":"No negative weight edges Description: Maintain distance estimate for every node Add neighbours and their distances into priority queue Remove node with smallest distance, visit its neighbours Done when priority queue is empty Final node will have its shortest distance static class iPair { int first, second; iPair(int first, int second) { this.first = first; this.second = second; } } void shortestPath(int src, int[][] graph) { // Sets up priority queue that compares distance of nodes, shorter distance first PriorityQueue<iPair> pq = new PriorityQueue<>(V, Comparator.comparingInt(o -> o.second)); int[] dist = new int[V]; Arrays.fill(dist, Integer.MAX_VALUE); pq.add(new iPair(0, src)); dist[src] = 0; while (!pq.isEmpty()) { // u is the value of the node with minimum distance int u = pq.poll().first; // for all neighbour of u for (int[] neighbour : graph[u]) { iPair v = new iPair(neighbour[0], neighbour[1]); int newDistance = dist[u] + v.second; if (dist[v.first] > newDistance) { dist[v.first] = newDistance; pq.add(new iPair(v.first, dist[v.first])); } } } for (int i = 0; i < V; i++) { System.out.println(i + dist[i]); } } Using AVL Tree priority queue Running time: O(E logV) insert: O(logn) deleteMin: O(logn) decreaseKey: O(logn) contains(key): O(1) Performance","title":"Dijkstra's Algorithm"},{"location":"dsa-notes/dsa-notes/#minimum-spanning-trees","text":"A spanning tree with minimum weight Properties: No cycles If you cut an MST, the two pieces are both MSTs For every cycle, the maximum weight edge is not in the MST For every partition of the nodes, the minimum weight edge across the cut is in the MST For every vertex, the minimum outgoing edge is always in the MST (not true for maximum)","title":"Minimum Spanning Trees"},{"location":"dsa-notes/dsa-notes/#prims-algorithm","text":"Continually pick the smallest edge of every node visited Using AVL tree for priority queue: Running time: O(E log V) class Pair implements Comparable<Pair> { int v; int wt; Pair(int v, int wt) { this.v = v; this.wt = wt; } public int compareTo(Pair that) { return this.wt - that.wt; } } static int spanningTree(int V, int E, int edges[][]) { ArrayList<ArrayList<Pair>> adj = new ArrayList<>(); for(int i = 0; i < V; i++) { adj.add(new ArrayList<Pair>()); } for(int i = 0; i < edges.length; i++) { int u = edges[i][0]; // from node u int v = edges[i][1]; // to node v int wt = edges[i][2]; // of weight wt // Add all edges into adj adj.get(u).add(new Pair(v,wt)); adj.get(v).add(new Pair(u,wt)); } PriorityQueue<Pair> pq = new PriorityQueue<Pair>(); pq.add(new Pair(0,0)); int[] vis = new int[V]; int s = 0; while (!pq.isEmpty()) { Pair node = pq.poll(); int v = node.v; // curr node's value int wt = node.wt; // curr node's weight if (vis[v] == 1) { continue; // if node is visited, skip } // node was not visited before s += wt; vis[v] = 1; for(Pair it : adj.get(v)) { if(vis[it.v] == 0) { pq.add(new Pair(it.v, it.wt)); } } } return s; }","title":"Prim's Algorithm"},{"location":"dsa-notes/dsa-notes/#kruskals-algorithm","text":"Sort all edges by weight, take all the minimum edges as long as there are no cycles Running time: O(E logV) static class Subset { int parent, rank; public Subset(int parent, int rank) { this.parent = parent; this.rank = rank; } } static class Edge { int src, dest, weight; public Edge(int src, int dest, int weight) { this.src = src; this.dest = dest; this.weight = weight; } } private static int findRoot(Subset[] subsets, int i) { if (subsets[i].parent == i) { return subsets[i].parent; } subsets[i].parent = findRoot(subsets, subsets[i].parent); return subsets[i].parent; } private static void union(Subset[] subsets, int x, int y) { int rootX = findRoot(subsets, x); int rootY = findRoot(subsets, y); if (subsets[rootY].rank < subsets[rootX].rank) { subsets[rootY].parent = rootX; } else if (subsets[rootX].rank < subsets[rootY].rank) { subsets[rootX].parent = rootY; } else { subsets[rootY].parent = rootX; subsets[rootX].rank++; } } private static void kruskals(int V, List<Edge> edges) { int j = 0; int noOfEdges = 0; Subset subsets[] = new Subset[V]; Edge results[] = new Edge[V]; // Create V subsets with single elements for (int i = 0; i < V; i++) { subsets[i] = new Subset(i, 0); } while (noOfEdges < V - 1) { // Edges are sorted in ascending order // Pick the smallest edge Edge nextEdge = edges.get(j); int x = findRoot(subsets, nextEdge.src); int y = findRoot(subsets, nextEdge.dest); // If cycle, root is the same if (x != y) { results[noOfEdges] = nextEdge; union(subsets, x, y); noOfEdges++; } j++; } int minCost = 0; for (int i = 0; i < noOfEdges; i++) { System.out.println(results[i].src + \" -- \" + results[i].dest + \" == \" + results[i].weight); minCost += results[i].weight; } System.out.println(\"Total cost of MST: \" + minCost); }","title":"Kruskal's Algorithm"},{"location":"dsa-notes/dsa-notes/#dynamic-programming","text":"Bottom up Solve smallest problems Combine smaller problems Solve root problem Top down Start at root and recurse Recurse Solve and memoize","title":"Dynamic Programming"},{"location":"dsa-notes/dsa-notes/#topological-sort","text":"Using DFS to find cycles and add to stack Verifies if the graph given is a directed acyclic graph (DAG) class Solution { HashMap<Integer, LinkedList<Integer>> adj = new HashMap<>(); HashMap<Integer, Boolean> visited = new HashMap<>(); Stack<Integer> stack = new Stack<>(); boolean isImpossible = false; public void addEdge(int v, int w) { adj.putIfAbsent(v, new LinkedList<>()); adj.putIfAbsent(w, new LinkedList<>()); adj.get(v).add(w); } private void dfsHelper(Integer v, HashMap<Integer, Boolean> visited1) { visited.put(v, true); visited1.put(v, true); // Traverse neighbours for (Integer i: adj.get(v)) { if (visited1.containsKey(i)) { isImpossible = true; // there is a cycle break; } if (!visited.get(i)) { dfsHelper(i, visited1); } } visited1.remove(v); stack.push(v); } public int[] findOrder(int numCourses, int[][] prerequisites) { int[] res = new int[numCourses]; Arrays.setAll(res, i -> i); if (prerequisites.length == 0) { return res; } // Add all edges into graph adj for (int[] prerequisite : prerequisites) { addEdge(prerequisite[1], prerequisite[0]); } // Set all keys to visited = false for (Integer key: adj.keySet()) { visited.put(key, false); } // Start DFS for (Integer key: adj.keySet()) { HashMap<Integer, Boolean> visited1 = new HashMap<>(); if (visited.get(key) == false) { dfsHelper(key, visited1); } } if (isImpossible) { return new int[0]; } HashMap<Integer, Integer> hm = new HashMap<>(); for (int i = 0; i < numCourses; i++) { hm.put(i, i); } // Add sorted courses into array int n = stack.size(); for (int i = 0; i < n; i++) { int course = stack.pop(); res[i] = course; hm.remove(course); } // Fill in the rest of the array with the missing courses int[] left = hm.keySet().stream().mapToInt(Integer::intValue).toArray(); int i1 = 0; int i2 = n; while (i1 < left.length && n < numCourses) { res[i2] = left[i1]; i1++; i2++; } return res; } }","title":"Topological Sort"}]}